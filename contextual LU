============
0701
Weekly scrum for Contextual LU / Teams file search
============

Hi Ming,

All model files and CMF files are under
\\corl\contextual-lu\model files

And how to run experiments are in the OneNote page:
Experiments How To  (Web view)  (這個是怎麼run evaluation test)


? 有空可以看一下

============
07262019
============

目前在teams 的contexual lu 的featurizer

[qd_teams_MV1_contextual_lu_featurizer]
PipelineBaseFilename=luna_teams_enus_mv1.contextual
luna_teams_enus_mv1_contextual.domain.pattern.fst
目前只有影響domain

teams_contextual_lu_domain.infile

ExternalFeatureSet:UserFileNames  
用到這個UserFileNames
? 要問一下這個怎麼存

output 1
UserFileNamesMatched
這個可以用在slots
[qd_teams_slots_lccrf_featurizer]
一般的slots_lccrf 沒有feautre 這邊可以學習建feature



實際的測試
open TeslaFile\tFEATURE.CLUTEAMS\t0\t1\t1\t1\t-1\t-1\tUserFileNames\t0\t1\tTeslaFile\t1\t-1
來看這個featurizer

這個純粹是string match 沒有pattern
output 1 = 
        Output:
                UserFileNamesMatched (tag: 2, string: 0)
                        0[0,0]=1
                        7[1,1]=1
                        
                  7 是mapped 過的tag number 用來target MagicFileName 有點像是 placeholder 
        這個是feature set slot crf 會用來train
output 2
teams_domain_fst_lang_model

fst pattern 
這個可以幫助domain score


BOS
似乎在apply pattern 前都要加BOS 這樣tag 才會正確

7 是mapped 過的tag number 用來target MagicFileName 有點像是 placeholder 

這邊目前只target 一個 scenario open xxx

可能以後會延伸

MagicFileName 的來源  runtime code  (shotbit 可以handle他)


有doman rule  for fileOpen
open MagicFileName



實際的測試
open TeslaFile\tFEATURE.CLUTEAMS\t0\t1\t1\t1\t-1\t-1\tUserFileNames\t0\t1\tTeslaFile\t1\t-1
來看這個featurizer



[qd_teams_slots_lccrf_featurizer]
luna_teams_enus_mv1.slot.model




跟一般的slots lccrf 相比

多了
        //複製input feature
	FeatureReplicate --in=ExternalInput2 --out=S_Teams_Contextual_File_Name --xform=span
        除了copy 也會修改tag[0,1] => [1, 1]
        FeatureReplicate --in=lccrf_ngram_2gram --out=lccrf_ngram_2gram_replicate --xform=to
        Inputs:
                lccrf_ngram_2gram (tag: 4, string: 0)
                        7138[0,1]=1
                        81959[1,2]=1
                        17039[2,3]=1
                        12092[3,4]=1
        Output:
                lccrf_ngram_2gram_replicate (tag: 4, string: 0)
                        7138[1,1]=1
                        81959[2,2]=1
                        17039[3,3]=1
                        12092[4,4]=1	

        
        //index 像後shift 1
        FeatureShifter --in=S_Teams_Contextual_File_Name --out=P1_S_Teams_Contextual_File_Name --shift=1
        //index 像後shift 2
	FeatureShifter --in=S_Teams_Contextual_File_Name --out=P2_S_Teams_Contextual_File_Name --shift=2
        //index 像前shoft 1
	FeatureShifter --in=S_Teams_Contextual_File_Name --out=N1_S_Teams_Contextual_File_Name --shift=-1
        //index 像前shoft 2
	FeatureShifter --in=S_Teams_Contextual_File_Name --out=N2_S_Teams_Contextual_File_Name --shift=-2

        // P1_S_Teams_Contextual_File_Name 跟原本的lccrf 1_gram 給合併
	FeatureConjunction --in=P1_S_Teams_Contextual_File_Name,lccrf_ngram_1gram --out=P1_S_CONJ_1gram_P1_S_Teams_Contextual_File_Name_lccrf_ngram_1gram --WeightOperator=max
        
        
        // 新家了這些feature
        // P2_S_Teams_Contextual_File_Name + N1_S_Teams_Contextual_File_Name + N2_S_Teams_Contextual_File_Name
        // P1_S_CONJ_1gram_P1_S_Teams_Contextual_File_Name_lccrf_ngram_1gram
        
        // 為什麼要shift 不太懂
        SparseLinearChainCRF
        https://msasg.visualstudio.com/QAS/_git/qas?path=%2Fprivate%2Fanswers%2FSDS%2FQCS%2Flib%2Fsrc%2Fmlg3.4%2Fdoc%2FSparseLinearChainCRF.md&version=GBmaster
        

        矩陣要乘的時候  要考慮1-gram 2 gram 3 gram 
	MaaFNGramFeaturizer 這個
	
	// old case wrong
	ngram_range(1,1) = 只有one gram feature
	        Inputs:
                ExternalInput1 (tag: 0, string: 2)
                        open[0,0]=1
                        teslafile[1,1]=1
        Output:
                lccrf_ngram_1gram (tag: 1, string: 0)
                        12[0,0]=1
			
		1 是word open one hot encoding 合併的表示法
		(teslafile 不再)

        //new case correct
	// 1 gram
	0: MaaFNGramFeaturizer --in=ExternalInput1 --out=lccrf_ngram_1gram --order=1 --bin=luna_teams_enus_mv1.lccrf.ngram.1gram.bin
        Inputs:
                ExternalInput1 (tag: 0, string: 4)
                        cortana[0,0]=1
                        launch[1,1]=1
                        teslafile[2,2]=1
                        please[3,3]=1
        Output:
                lccrf_ngram_1gram (tag: 3, string: 0)
                        1542[0,0]=1
                        1557[1,1]=1
                        372[3,3]=1	
		word 有自己的 one hoting encoding 表示法
	        teslafile 不存在bag of word(因為是從bin的library 中決定)
		default WITHOUT CAPTUREBOUNDARY
		? 但是為什麼不是2 的倍數?  我猜他是372 的bit = 1
		
			
	// 2 gram
        MaaFNGramFeaturizer --in=ExternalInput1 --out=lccrf_ngram_2gram --order=2 --bin=files_enus_mv1.lccrf.ngram.2gram.bin
        Inputs:
                ExternalInput1 (tag: 0, string: 5)
                        excel[0,0]=1
                        sheet[1,1]=1
                        shared[2,2]=1
                        in[3,3]=1
                        shiproom[4,4]=1
        Output:
                lccrf_ngram_2gram (tag: 4, string: 0)
                        7138[0,1]=1
                        81959[1,2]=1
                        17039[2,3]=1
                        12092[3,4]=1
         
        // 3 gram
        MaaFNGramFeaturizer --in=ExternalInput1 --out=lccrf_ngram_3gram --order=3 --bin=files_enus_mv1.lccrf.ngram.3gram.bin
        Inputs:
                ExternalInput1 (tag: 0, string: 5)
                        excel[0,0]=1
                        sheet[1,1]=1
                        shared[2,2]=1
                        in[3,3]=1
                        shiproom[4,4]=1
        Output:
                lccrf_ngram_3gram (tag: 3, string: 0)
                        81960[0,2]=1
                        81961[1,3]=1
                        81962[2,4]=1



linear CRF
CRF 的變形

https://blog.csdn.net/aws3217150/article/details/68935789
对于一段输入文字“The dog barks”，我们希望获得他的词性标注“The/D(冠词) dog/N(名词) barks/V(动词)”。
也就是对于一段输入序列x⃗ =[x1,x2,....,xn]x→=[x1,x2,....,xn],
我们希望获得相应的特定任务的输出序列s⃗ =[s1,s2,...,sn]s→=[s1,s2,...,sn]。比如刚刚举的词性标注例子，
此时xnxn将对应字典集VV里面的词，snsn则是词性集SS里面的元素

s:  token output state
x : token labeled data (不是model output)

in QAS CRF
1-gram
    shift 1
    shift 2
    shift 3
    shift -1
    shift -2
2-gram
    shift 1
    shift -1
    shift -2
lexicon
     shift 1
     shift 2
     shift -1
     shift -2
     
FeatureConjunction
      lexicon + 1-gram
      這個事生成另外一個 hashtag
      hashtag id 不一定
      根據page
      (intent, unigram) -> intent-specific unigram
      這邊是
      (lexicon, unigram) -> lexicon-specific unigram 

      輸出後一個token position 是有可能會有多個tag的 因為
      lexicon 本來就會有多個
      https://msasg.visualstudio.com/QAS/_git/qas?path=%2Fprivate%2Fanswers%2FSDS%2FQCS%2Flib%2Fsrc%2Fmlg3.4%2FDUFeatureConjunction.cpp&version=GBmaster
      根據code, 用first set(lexicon 當作主體)  len 決定要輸出幾個

SparseLinearChainCRF
      1-gram ,  1-gram(shift 1,2,3,-1,-2)
      2-gram, 2-gram(shift 1,2,-1,-2)
      lexicon, lexicon(shift 1,2,-1,-2)
      (lexicon, unigram) -> lexicon-specific unigram 
      
      生成一個final tag
      並不是用哪個為準
      ? 目前怎麼work 還不太確定
      




