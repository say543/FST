https://msasg.visualstudio.com/DefaultCollection/Cortana/_git/CoreScience/pullrequest/1001644?_a=files


https://microsoft.sharepoint.com/teams/LUforNextgenAgents/_layouts/15/WopiFrame.aspx?sourcedoc={68deb809-671e-469a-be79-ba53c05298ce}&action=edit&wd=target%28Task%20Understanding%2FLearning%20Manual.one%7C438f2f70-0bdc-4aaa-885e-d1ab739ec857%2FDeep%20Tagger%20%28Bi-LSTM%20%2B%20CRF%5C%29%7C7072b692-7c86-4b55-b078-589bcb670655%2F%29

<one note document>

==================================
one note 
enlist to search gold 
================================


要先enlist
E:\searchGold 
現在可以查

follow 1., 2.
then 
get
You are now enlisted in the searchgold sources on the BSDSearchGold:7727 SD server.

The shortcut "CoReXT searchgold AMD64" has been placed on your desktop.
Use this link to open a retail build window and use your enlistment.





then
set the client view 
open icon cortext searchgold bsdsearchgold
	Ø Open the corext shortcut (should  be search gold icon in your desktop)  and type
sd client (in your directory , eg: E:\corext\searchgold>)  

will open 一個txt
加成這樣

E:\searchgold>sd client






View:


- 是comment  但是不能全部一起做  否則太慢

	//depot/... //DESKTOP-3J7614O-searchgold-1/...
	//depot/AutopilotService/... //DESKTOP-3J7614O-searchgold-1/AutopilotService/...
	//depot/Dapple/... //DESKTOP-3J7614O-searchgold-1/depot/Dapple/...
	//depot/deploy/... //DESKTOP-3J7614O-searchgold-1/deploy/...
	//depot/dev/... //DESKTOP-3J7614O-searchgold-1/dev/...
	//depot/deploy/builds/data/answers/QAS01HttpQAS/... //DESKTOP-3J7614O-searchgold-1/deploy/builds/data/answers/QAS01HttpQAS/...
	//depot/tools/... //DESKTOP-3J7614O-searchgold-1/tools/...
	//depot/public/... //DESKTOP-3J7614O-searchgold-1/public/...
	//depot/deploy/builds/data/latest/test/machinelearning/qcs/... //DESKTOP-3J7614O-searchgold-1/deploy/builds/data/latest/test/machinelearning/qcs/...
	//depot/deploy/builds/data/latest/test/machinelearning/mlg/... //DESKTOP-3J7614O-searchgold-1/deploy/builds/data/latest/test/machinelearning/mlg/...
	//depot/deploy/builds/data/answers/XapQuServiceAnswer/... //DESKTOP-3J7614O-searchgold-1/deploy/builds/data/answers/XapQuServiceAnswer/...
	//depot/deploy/builds/data/answers/QASECPrebuilt/... //DESKTOP-3J7614O-searchgold-1/deploy/builds/data/answers/QASECPrebuilt/...


先生成需要的directory
(不能整個search gold 一起sync 那樣檔案會太大)
注意正負斜線

[question]
? 要問一下這些model 的output 是從哪邊來的  以後能不能用
Sd sync -f deploy\builds\data\answers\QAS01HttpQAS\...

Sd sync -f deploy\builds\data\answers\QASECPrebuilt\...

Sd sync -f deploy\builds\data\answers\XapQuServiceAnswer\...

Sd sync -f deploy\builds\data\latest\test\machinelearning\mlg\...
Sd sync -f deploy\builds\data\latest\test\machinelearning\qcs\...

===================================

Deep Tagger (Bi-LSTM)
MovieTv DeepTagger
two one note documents


=============================

prrequisties
這步沒有問題

Download pre-trained GloVe word embeddings 

    Open Windows Bash shell 

    CD  private/PersonalAssistant/Offline/DeepTagger/BiLSTM-CRF/ 

    wget -P ./data/ http://nlp.stanford.edu/data/glove.6B.zip 

    unzip ./data/glove.6B.zip -d ./data/glove.6B/ 

==> Make sure the "data\glove.6B" directory exists under private\PersonalAssistant\Offline\DeepTagger\BiLSTM-CRF 

執行這個
PS E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts> .\Prepare.ps1 -Domain movietv -Searchgold E:\searchgold -MlgToolsDir E:\mercury\public\ext\Carina\MLGTools

release build 
Make sure the "release" directory exists under private\PersonalAssistant\Offline\DeepTagger\Scripts 

[question]
? release folder 看起來像是 要生成qpc 相關的file
這個怎麼work 還真的不知道

#三個enlistment 都要存在
 foreach ($dir in ("QAS01HttpQAS", "XapQuServiceAnswer", "QASECPrebuilt"))


#Build Train/Dev/Test datasets#

private\PersonalAssistant\Offline\DeepTagger\NerProcesor\
這邊build 生成 .ext

NerProcessor 這個code 可能可以留著
在這邊建experiments 存data set 
private\PersonalAssistant\Offline\DeepTagger\NerProcesor\experiments

movietv-10k.annotated.train-0.tsv 
	E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts\movietv\datasets\movietv-10k.annotated.train-0.tsv

	Subset of Movie-10K.tsv annotated set used for training 
	
	

movietv-10k.annotated.test-0.tsv 
	E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts\movietv\datasets\movietv-10k.annotated.test-0.tsv

	Subset of Movie-10K.tsv annotated set used for model validation/testing 

negatives-500.annotated.tsv 
	
	E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts\movietv\datasets\negatives-500.annotated.tsv

	Top 500 negative queries (e.g. useful to avoid precision errors) 

synthetic-train.annotated.tsv 
        E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts\movietv\datasets\synthetic-train.annotated.tsv
	
	2K synthetic queries generated using Learning's Synthetic Query Generator tool 
        這個tool 因該是可以改善 用yue 的pipeline

movietv-measurement-blind.annotated.tsv 
	
        E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts\movietv\datasets\movietv-measurement-blind.annotated.tsv

	Blind set for measurement & metrics reporting.  
	
	
#Lexicons#
private\PersonalAssistant\Offline\DeepTagger\Scripts\movietv\lexicons  
luna.lexicon.movieTvActors.txt 
luna.lexicon.movieTvTitles.txt 
原本就在report 裡面  不需要做任何的動作


這個可以開始project 然後看view
PS E:\mercury\private\PersonalAssistant\Offline\DeepTagger\NerProcesor> .\NerProcessor.csproj

private\PersonalAssistant\Offline\DeepTagger\NerProcesor\bin\Debug\NerProcessor.exe Ner 
--op Preprocess 
--inputDir E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts\movietv\datasets 
--inputFile movietv-10k.annotated.train-0.tsv 
// output 的位置
--outputDir .\experiments\deep-tagging\movietv 
--domain movietv 
--annotationFormat lu 
--useQcsFeaturizer 
// 舊版本  現在可能要用gauruish share 的
// 現在在下面
// --qcsToolsPath E:\CxCache\QcsQueryLabelWithTFSupport.1.0.1\ 
--qcsToolsPath .\QcsQueryLabelTool-vL\
// 這個是讀前面的release directory 的位置
--qcsConfigDir E:\mercury\private\PersonalAssistant\Offline\DeepTagger\Scripts\release
--tokenizer WhitespaceTokenizer 

 

生成出來的files name 會叫做
movietv-10k.annotated.test-0.features.seq.tsv
for one column
token / slot(O) / one-hot emcoding 

[question]
如果是這樣 其實我們根本不需要Ner processor 自己生成這個column 就行了

wish	B-media_title	0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
list.	O	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0





Train a DNN model 
data_base_dir 
	

Path to directory with all DNN model datasets (e.g *.features.seq.tsv) 


result_base_dir 
	

Path to directory to output trained model 

我改成這樣
	data_base_dir = 'E:\\mercury\\private\\PersonalAssistant\\Offline\\DeepTagger\\NerProcesor\\experiments\\deep-tagging\\movietv'
	result_base_dir = 'E:\\mercury\\private\\PersonalAssistant\\Offline\\DeepTagger\\trained_model'


可以用這個visual studio 開啟這個project
E:\mercury\private\PersonalAssistant\Offline\DeepTagger\BiLSTM-CRF\BiLSTM-CRF.pyproj

有build / train / Ner 等等的code base 這些都可以一次access 看code    




需要自己 create python enviroment 
自己creaate 一個virtual emviroment

py -m venv BiLSTM-CRF-env
then active
.\BiLSTM-CRF-env\Scripts\activate

要install numpy
要install tensorflow

python build_data.py --domain movietv 
This generates the words_<DOMAIN>.txt (vocab file) based on train/dev/test datasets 


在這個下面
跟input.seq.tsv 的file 在同一個ddirectory 
./private/PersonalAssistant/Offline/DeepTagger/NerProcesor/experiments/deep-tagging/movietv/words_movietv.txt

 Generates 4 files:  
 (1) words_movietv.txt, 
     感覺是所有的vocabulary list 
 (2) chars_movietv.txt 
     感覺是所有的character list 
 (3) tags_movietv.txt and 
      感覺是所有的tag (包含沒有tag 的狀況)
      [question]
      沒有BOS , EOS
      不知道train 的時候會不會有
      
 (4) glove.6B.100d.movietv_eval.npz 
     [questions]
      這個不知道是什麼  可能之後要問一下
 

[question]
會讀data sets 
跟讀glove 的embedding
   by filename_glove
這個flow 因該也可以變得更好



(BiLSTM-CRF-env) PS E:\mercury\private\PersonalAssistant\Offline\DeepTagger\BiLSTM-CRF> py build_data.py --domain movietv
Building word and tag vocab...
- done. 7553 tokens
Building glove vocab...
- done. 400000 tokens
Writing vocab...
- done. 5983 tokens
Writing vocab...
- done. 5 tokens
Building char vocab...
- done. 62 tokens
Writing vocab...
- done. 62 tokens

[question]
這個是主要在train model 可以研究model
py main.py --domain movietv --train 

class NERModel()
這個會build tensor flow 的 model
build(self) 這個會見一堆的model

E:\mercury\private\PersonalAssistant\Offline\DeepTagger\trained_model\bilstm-crf-noChar-h100-w100   
裡面有所有tensor flow weight 的相關files
tensorflow 的檔案看不懂

from result_base_dir = 'E:\\mercury\\private\\PersonalAssistant\\Offline\\DeepTagger\\trained_model'


#evaluate  model 的結果#
py main.py --domain movietv --evaluate

會生成file
eval_output_movietv-10k.annotated.test-0.features.seq.media_person.tsv

直接輸出這樣
Cortana,	O	O
play	O	O
The	O	O
Way	O	O
You	O	O
Make	O	O
Me	O	O
Feel	O	O
by	O	O
Michael	B-media_person	B-media_person
Jackson	I-media_person	I-media_person
.	O	O

Cortana	O	O
play	O	O
the	B-media_title	B-media_title
dark	I-media_title	I-media_title
knight	I-media_title	I-media_title
rises	I-media_title	I-media_title
from	O	O
netflix	O	O


[question]
不知道為什麼tagger 要走兩個 columb
我猜一個是expected annotation  
    ? 第一個看code 還不太確定
第二一個是slot tagger 的預測結果




eval_output_movietv-10k.annotated.test-0.features.seq.media_title.tsv
eval_output_movietv-10k.annotated.test-0.features.seq.tsv

[question]
不知道為什麼要三個files 

#這邊主要是要Export to QAS#

py export_model.py 
// tensorflow 讀graph
--meta_file  E:\mercury\private\PersonalAssistant\Offline\DeepTagger\trained_model\bilstm-crf-noChar-h100-w100\model.weights\.meta  
--model_file E:\mercury\private\PersonalAssistant\Offline\DeepTagger\trained_model\bilstm-crf-noChar-h100-w100\model.weights\  

// 用 result_base_dir 來取代
--export_path E:\mercury\private\PersonalAssistant\Offline\DeepTagger\DeepModelQas


[question 為什麼要讀近來  在builder 到一個output ]


