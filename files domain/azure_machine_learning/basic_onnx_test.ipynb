{
 "cells": [
  {
   "source": [
    "https://pytorch.org/docs/stable/onnx.html#example-end-to-end-alexnet-from-pytorch-to-onnx\n",
    "\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py\n",
    "\n",
    "https://pytorch.apachecn.org/docs/1.0/onnx.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "graph(%0 : Long(2:5, 5:1, requires_grad=0, device=cpu)):\n  %2 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n  %3 : Long(2:5, 5:1, requires_grad=0, device=cpu) = onnx::Add(%0, %2)\n  %4 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %5 : Long(2:5, 5:1, requires_grad=0, device=cpu) = onnx::Add(%3, %4)\n  %6 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %7 : Long(2:5, 5:1, requires_grad=0, device=cpu) = onnx::Add(%5, %6)\n  %8 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %9 : Long(2:5, 5:1, requires_grad=0, device=cpu) = onnx::Add(%7, %8)\n  %10 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]()\n  %11 : Long(2:5, 5:1, requires_grad=0, device=cpu) = onnx::Add(%9, %10)\n  return (%11)\n\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Trace-based only\n",
    "\n",
    "class LoopModel(torch.nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        for i in range(y):\n",
    "            x = x + i\n",
    "        return x\n",
    "\n",
    "model = LoopModel()\n",
    "\n",
    "#offical example\n",
    "# pass\n",
    "#dummy_input = torch.ones(2, 3, dtype=torch.long)\n",
    "#loop_count = torch.tensor(5, dtype=torch.long)\n",
    "# my test\n",
    "#also work , two parameters\n",
    "dummy_input = torch.ones(2, 5, dtype=torch.long)\n",
    "loop_count = torch.tensor(5, dtype=torch.long)\n",
    "\n",
    "\n",
    "torch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True)"
   ]
  },
  {
   "source": [
    "https://pytorch.org/docs/stable/onnx.html#example-end-to-end-alexnet-from-pytorch-to-onnx\n",
    "scrip-based exporter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "graph(%input_data : Long(2:3, 3:1, requires_grad=0, device=cpu),\n      %loop_range : Long(requires_grad=0, device=cpu),\n      %10 : Bool(requires_grad=0, device=cpu)):\n  %2 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %4 : Long(2:3, 3:1, requires_grad=0, device=cpu) = onnx::Loop(%loop_range, %10, %input_data) # <ipython-input-5-e5e16e1b7555>:5:4\n    block0(%i.1 : Long(device=cpu), %cond : bool, %x.6 : Long(2:3, 3:1, requires_grad=0, device=cpu)):\n      %8 : LongTensor = onnx::Add(%x.6, %i.1) # <ipython-input-5-e5e16e1b7555>:6:12\n      %9 : bool = onnx::Cast[to=9](%2)\n      -> (%9, %8)\n  return (%4)\n\n"
     ]
    }
   ],
   "source": [
    "# Mixing tracing and scripting\n",
    "\n",
    "@torch.jit.script\n",
    "def loop(x, y):\n",
    "    for i in range(int(y)):\n",
    "        x = x + i\n",
    "    return x\n",
    "\n",
    "class LoopModel2(torch.nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        return loop(x, y)\n",
    "\n",
    "model = LoopModel2()\n",
    "dummy_input = torch.ones(2, 3, dtype=torch.long)\n",
    "loop_count = torch.tensor(5, dtype=torch.long)\n",
    "torch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True,\n",
    "                  input_names=['input_data', 'loop_range'])"
   ]
  },
  {
   "source": [
    "apply_chunking_to_forward test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "#enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "enc = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "#text = \"[CLS] Who was Jim Henson ?\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "\n",
    "# for deubg\n",
    "print(\"tokenized_text: {}\".format(tokenized_text))\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "print(\"indexed_tokens: {}\".format(indexed_tokens))\n",
    "segments_ids = [0]\n",
    "\n",
    "# Creating a dummy input\n",
    "# but you need to move tensors to GPU\n",
    "#https://github.com/huggingface/transformers/issues/227\n",
    "# discuss convertion\n",
    "#https://discuss.pytorch.org/t/best-way-to-convert-a-list-to-a-tensor/59949/2\n",
    "#torch.tensor\n",
    "#tokens_tensor = torch.tensor([indexed_tokens])\n",
    "#segments_tensors = torch.tensor([segments_ids])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"create input for device: {}\".format(device))\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "dummy_input = tokens_tensor\n",
    "\n",
    "\n",
    "# for debug\n",
    "print(\"tokens_tensor shape for chunk: {}\".format(tokens_tensor[0].shape[0])) \n",
    "for token_tensor in tokens_tensor:\n",
    "    print(\"token_tensor shape for chunk: {}\".format(token_tensor.shape[0]))\n",
    "\n",
    "\n",
    "# for deubg\n",
    "# 14 tokens for output\n",
    "print(\"tokens_tensor shape: {}\".format(tokens_tensor.shape))\n",
    "print(\"segments_tensor shape: {}\".format(segments_tensors.shape))\n",
    "\n",
    "print(\"tokens_tensor: {}\".format(tokens_tensor))\n",
    "print(\"segments_tensor: {}\".format(segments_tensors))\n",
    "\n",
    "\n",
    "# Initializing the model with the torchscript flag\n",
    "# Flag set to True even though it is not necessary as this model does not have an LM Head.\n",
    "#config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "#    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, torchscript=True)\n",
    "\n",
    "# Instantiating the model\n",
    "#model = BertModel(config)\n",
    "\n",
    "# The model needs to be in evaluation mode\n",
    "#model.eval()\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "# classfication only  0 and 1 so set ut to 2\n",
    "num_labels = 2\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels,\n",
    "                                                            output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.onnx.export(model, dummy_input, 'traced_distill_bert.onnx', verbose=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex net\n",
    "https://medium.com/@whyaitchyou/alexnet-%E6%9E%B6%E6%A7%8B%E6%A6%82%E8%BF%B0-988113c06b4b\n",
    "https://zhuanlan.zhihu.com/p/51387600\n",
    "https://github.com/onnx/tutorials/blob/master/tutorials/PytorchOnnxExport.ipynb\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using torchscript to output pytroch model\n",
    "# original example\n",
    "\n",
    "#output to onnx\n",
    "#https://huggingface.co/transformers/serialization.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenized_text: ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
      "tokens_tensor: torch.Size([1, 14])\n",
      "segments_tensor: torch.Size([1, 14])\n",
      "graph(%self.1 : __torch__.transformers.modeling_bert.___torch_mangle_1668.BertModel,\n",
      "      %input_ids : Long(1:14, 14:1, requires_grad=0, device=cpu),\n",
      "      %attention_mask.1 : Long(1:14, 14:1, requires_grad=0, device=cpu)):\n",
      "  %3393 : __torch__.transformers.modeling_bert.___torch_mangle_1667.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)\n",
      "  %3388 : __torch__.transformers.modeling_bert.___torch_mangle_1664.BertEncoder = prim::GetAttr[name=\"encoder\"](%self.1)\n",
      "  %2979 : __torch__.transformers.modeling_bert.___torch_mangle_1458.BertEmbeddings = prim::GetAttr[name=\"embeddings\"](%self.1)\n",
      "  %634 : int = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:795:0\n",
      "  %635 : int = aten::size(%input_ids, %634) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:795:0\n",
      "  %636 : Long(device=cpu) = prim::NumToTensor(%635)\n",
      "  %640 : int = aten::Int(%636)\n",
      "  %637 : int = prim::Constant[value=1]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:795:0\n",
      "  %638 : int = aten::size(%input_ids, %637) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:795:0\n",
      "  %639 : Long(device=cpu) = prim::NumToTensor(%638)\n",
      "  %641 : int = aten::Int(%639)\n",
      "  %642 : int[] = prim::ListConstruct(%640, %641)\n",
      "  %643 : int = prim::Constant[value=4]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:806:0\n",
      "  %644 : None = prim::Constant()\n",
      "  %645 : Device = prim::Constant[value=\"cpu\"]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:806:0\n",
      "  %646 : bool = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:806:0\n",
      "  %input.2 : Long(1:14, 14:1, requires_grad=0, device=cpu) = aten::zeros(%642, %643, %644, %645, %646) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_bert.py:806:0\n",
      "  %648 : int = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %649 : int = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %650 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %651 : int = prim::Constant[value=1]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %652 : Long(1:14, 14:1, requires_grad=0, device=cpu) = aten::slice(%attention_mask.1, %648, %649, %650, %651) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %653 : int = prim::Constant[value=1]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %654 : Long(1:14, 1:14, 14:1, requires_grad=0, device=cpu) = aten::unsqueeze(%652, %653) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %655 : int = prim::Constant[value=2]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %656 : Long(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = aten::unsqueeze(%654, %655) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %657 : int = prim::Constant[value=3]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %658 : int = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %659 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %660 : int = prim::Constant[value=1]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %extended_attention_mask : Long(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = aten::slice(%656, %657, %658, %659, %660) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:244:0\n",
      "  %662 : int = prim::Constant[value=6]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:257:0\n",
      "  %663 : bool = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:257:0\n",
      "  %664 : bool = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:257:0\n",
      "  %665 : None = prim::Constant()\n",
      "  %666 : Float(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = aten::to(%extended_attention_mask, %662, %663, %664, %665) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:257:0\n",
      "  %667 : float = prim::Constant[value=1.]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:511:0\n",
      "  %668 : int = prim::Constant[value=1]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:511:0\n",
      "  %669 : Float(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = aten::rsub(%666, %667, %668) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:511:0\n",
      "  %670 : Double(requires_grad=0, device=cpu) = prim::Constant[value={-10000}]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:258:0\n",
      "  %attention_mask : Float(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = aten::mul(%669, %670) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_utils.py:258:0\n",
      "  %3608 : Tensor = prim::CallMethod[name=\"forward\"](%2979, %input_ids, %input.2)\n",
      "  %3609 : Tensor = prim::CallMethod[name=\"forward\"](%3388, %3608, %attention_mask)\n",
      "  %3610 : Tensor = prim::CallMethod[name=\"forward\"](%3393, %3609)\n",
      "  %2753 : (Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu), Float(1:768, 768:1, requires_grad=1, device=cpu)) = prim::TupleConstruct(%3609, %3610)\n",
      "  return (%2753)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "\n",
    "# for deubg\n",
    "print(\"tokenized_text: {}\".format(tokenized_text))\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "dummy_input = [tokens_tensor, segments_tensors]\n",
    "\n",
    "# for deubg\n",
    "# 14 tokens for output\n",
    "print(\"tokens_tensor: {}\".format(tokens_tensor.shape))\n",
    "print(\"segments_tensor: {}\".format(segments_tensors.shape))\n",
    "\n",
    "# Initializing the model with the torchscript flag\n",
    "# Flag set to True even though it is not necessary as this model does not have an LM Head.\n",
    "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, torchscript=True)\n",
    "\n",
    "# Instantiating the model\n",
    "#soruce code\n",
    "#https://huggingface.co/transformers/_modules/transformers/models/bert/modeling_bert.html#BertModel\n",
    "# but do not find @torch.jit.script_nmethod.... why it can works\n",
    "model = BertModel(config)\n",
    "\n",
    "# The model needs to be in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "\n",
    "# Creating the trace\n",
    "#https://pytorch.org/docs/stable/generated/torch.jit.trace.html\n",
    "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n",
    "\n",
    "print(traced_model.graph)\n",
    "# if want to want to download, uncomment it \n",
    "#torch.jit.save(traced_model, \"traced_bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using torchscript to output\n",
    "# change to distillation bert\n",
    "\n",
    "#output to onnx\n",
    "#https://huggingface.co/transformers/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenized_text: ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
      "tokens_tensor: torch.Size([1, 14])\n",
      "segments_tensor: torch.Size([1, 1])\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "graph(%self.1 : __torch__.transformers.modeling_distilbert.___torch_mangle_2424.DistilBertForSequenceClassification,\n",
      "      %input_ids : Long(1:14, 14:1, requires_grad=0, device=cpu)):\n",
      "  %1451 : __torch__.torch.nn.modules.linear.___torch_mangle_2422.Linear = prim::GetAttr[name=\"classifier\"](%self.1)\n",
      "  %1448 : __torch__.torch.nn.modules.dropout.___torch_mangle_2423.Dropout = prim::GetAttr[name=\"dropout\"](%self.1)\n",
      "  %1447 : __torch__.torch.nn.modules.linear.___torch_mangle_2421.Linear = prim::GetAttr[name=\"pre_classifier\"](%self.1)\n",
      "  %1444 : __torch__.transformers.modeling_distilbert.___torch_mangle_2420.DistilBertModel = prim::GetAttr[name=\"distilbert\"](%self.1)\n",
      "  %1540 : Tensor = prim::CallMethod[name=\"forward\"](%1444, %input_ids)\n",
      "  %1145 : int = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %1146 : int = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %1147 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %1148 : int = prim::Constant[value=1]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %1149 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = aten::slice(%1540, %1145, %1146, %1147, %1148) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %1150 : int = prim::Constant[value=1]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %1151 : int = prim::Constant[value=0]() # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %input.52 : Float(1:10752, 768:1, requires_grad=1, device=cpu) = aten::select(%1149, %1150, %1151) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %1541 : Tensor = prim::CallMethod[name=\"forward\"](%1447, %input.52)\n",
      "  %input.54 : Float(1:768, 768:1, requires_grad=1, device=cpu) = aten::relu(%1541) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1136:0\n",
      "  %1542 : Tensor = prim::CallMethod[name=\"forward\"](%1448, %input.54)\n",
      "  %1543 : Tensor = prim::CallMethod[name=\"forward\"](%1451, %1542)\n",
      "  %1165 : (Float(1:2, 2:1, requires_grad=1, device=cpu)) = prim::TupleConstruct(%1543)\n",
      "  return (%1165)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "#enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "enc = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "\n",
    "# for deubg\n",
    "print(\"tokenized_text: {}\".format(tokenized_text))\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "dummy_input = [tokens_tensor, segments_tensors]\n",
    "\n",
    "# for deubg\n",
    "# 14 tokens for output\n",
    "print(\"tokens_tensor shape: {}\".format(tokens_tensor.shape))\n",
    "print(\"segments_tensor shape: {}\".format(segments_tensors.shape))\n",
    "\n",
    "print(\"tokens_tensor: {}\".format(tokens_tensor.shape))\n",
    "print(\"segments_tensor: {}\".format(segments_tensors.shape))\n",
    "\n",
    "\n",
    "# Initializing the model with the torchscript flag\n",
    "# Flag set to True even though it is not necessary as this model does not have an LM Head.\n",
    "#config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "#    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, torchscript=True)\n",
    "\n",
    "# Instantiating the model\n",
    "#model = BertModel(config)\n",
    "\n",
    "# The model needs to be in evaluation mode\n",
    "#model.eval()\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "# classfication only  0 and 1 so set ut to 2\n",
    "num_labels = 2\n",
    "#model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels,\n",
    "#                                                            output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels,\n",
    "                                                            output_attentions=False, output_hidden_states=False,torchscript=True)\n",
    "\n",
    "\n",
    "#torch.onnx.export(model, dummy_input, 'traced_distill_bert.onnx', verbose=True)\n",
    "\n",
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model, tokens_tensor)\n",
    "print(traced_model.graph)\n",
    "\n",
    "# if want to want to download, uncomment it \n",
    "#torch.jit.save(traced_model, \"traced_distill_bert.pt\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "#remove torchscript\n",
    "# change to distillation bert\n",
    "#output to onnx\n",
    "# this one seems to work but this should be cpu version\n",
    "# if want , follow this code to move to gpu version to test\n",
    "# https://github.com/huggingface/transformers/issues/227\n",
    "#https://huggingface.co/transformers/serialization.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenized_text: ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
      "tokens_tensor shape: torch.Size([1, 14])\n",
      "segments_tensor shape: torch.Size([1, 1])\n",
      "tokens_tensor: tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]])\n",
      "segments_tensor: tensor([[0]])\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "graph(%input.1 : Long(1:14, 14:1, requires_grad=0, device=cpu),\n",
      "      %distilbert.embeddings.word_embeddings.weight : Float(30522:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.embeddings.position_embeddings.weight : Float(512:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.embeddings.LayerNorm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.embeddings.LayerNorm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %pre_classifier.weight : Float(768:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %pre_classifier.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %classifier.weight : Float(2:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %classifier.bias : Float(2:1, requires_grad=1, device=cpu),\n",
      "      %856 : Float(requires_grad=0, device=cpu),\n",
      "      %857 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %858 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %859 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %860 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %861 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %862 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %863 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %864 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %865 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %866 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %867 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %868 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %869 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %870 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %871 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %872 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %873 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %874 : Float(requires_grad=0, device=cpu),\n",
      "      %875 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %876 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %877 : Float(requires_grad=0, device=cpu),\n",
      "      %878 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %879 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %880 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %881 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %882 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %883 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %884 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %885 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %886 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %887 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %888 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %889 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %890 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %891 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %892 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %893 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %894 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %895 : Float(requires_grad=0, device=cpu),\n",
      "      %896 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %897 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %898 : Float(requires_grad=0, device=cpu),\n",
      "      %899 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %900 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %901 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %902 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %903 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %904 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %905 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %906 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %907 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %908 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %909 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %910 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %911 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %912 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %913 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %914 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %915 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %916 : Float(requires_grad=0, device=cpu),\n",
      "      %917 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %918 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %919 : Float(requires_grad=0, device=cpu),\n",
      "      %920 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %921 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %922 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %923 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %924 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %925 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %926 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %927 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %928 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %929 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %930 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %931 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %932 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %933 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %934 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %935 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %936 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %937 : Float(requires_grad=0, device=cpu),\n",
      "      %938 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %939 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %940 : Float(requires_grad=0, device=cpu),\n",
      "      %941 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %942 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %943 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %944 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %945 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %946 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %947 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %948 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %949 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %950 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %951 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %952 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %953 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %954 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %955 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %956 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %957 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %958 : Float(requires_grad=0, device=cpu),\n",
      "      %959 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %960 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %961 : Float(requires_grad=0, device=cpu),\n",
      "      %962 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %963 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %964 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %965 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %966 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %967 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %968 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %969 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %970 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %971 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %972 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %973 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %974 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %975 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %976 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %977 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %978 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %979 : Float(requires_grad=0, device=cpu),\n",
      "      %980 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %981 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %982 : Float(requires_grad=0, device=cpu)):\n",
      "  %105 : Tensor = onnx::Shape(%input.1)\n",
      "  %106 : Tensor = onnx::Constant[value={0}]()\n",
      "  %107 : Long(device=cpu) = onnx::Gather[axis=0](%105, %106) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:483:0\n",
      "  %108 : Tensor = onnx::Shape(%input.1)\n",
      "  %109 : Tensor = onnx::Constant[value={1}]()\n",
      "  %110 : Long(device=cpu) = onnx::Gather[axis=0](%108, %109) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:483:0\n",
      "  %111 : Tensor = onnx::Unsqueeze[axes=[0]](%107)\n",
      "  %112 : Tensor = onnx::Unsqueeze[axes=[0]](%110)\n",
      "  %113 : Tensor = onnx::Concat[axis=0](%111, %112)\n",
      "  %114 : Float(1:14, 14:1, requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={1}](%113) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:492:0\n",
      "  %115 : Tensor = onnx::Shape(%input.1)\n",
      "  %116 : Tensor = onnx::Constant[value={1}]()\n",
      "  %117 : Long(device=cpu) = onnx::Gather[axis=0](%115, %116) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:108:0\n",
      "  %118 : Tensor = onnx::Unsqueeze[axes=[0]](%117)\n",
      "  %119 : Tensor = onnx::ConstantOfShape[value={1}](%118)\n",
      "  %120 : Tensor = onnx::NonZero(%119)\n",
      "  %121 : Tensor = onnx::Transpose[perm=[1, 0]](%120)\n",
      "  %122 : Tensor = onnx::Squeeze[axes=[1]](%121)\n",
      "  %123 : Long(14:1, requires_grad=0, device=cpu) = onnx::Cast[to=7](%122) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:109:0\n",
      "  %124 : Long(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[0]](%123) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:110:0\n",
      "  %125 : Tensor = onnx::Shape(%input.1)\n",
      "  %126 : Long(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%124, %125) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:110:0\n",
      "  %127 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Gather(%distilbert.embeddings.word_embeddings.weight, %input.1) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1852:0\n",
      "  %128 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Gather(%distilbert.embeddings.position_embeddings.weight, %126) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1852:0\n",
      "  %129 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%127, %128) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:115:0\n",
      "  %131 : Tensor = onnx::ReduceMean[axes=[-1]](%129)\n",
      "  %132 : FloatTensor = onnx::Sub(%129, %131)\n",
      "  %133 : Tensor = onnx::Cast[to=1](%132)\n",
      "  %135 : Tensor = onnx::Pow(%133, %856)\n",
      "  %136 : Tensor = onnx::ReduceMean[axes=[-1]](%135)\n",
      "  %137 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %138 : FloatTensor = onnx::Add(%136, %137)\n",
      "  %139 : Tensor = onnx::Sqrt(%138)\n",
      "  %140 : FloatTensor = onnx::Div(%132, %139)\n",
      "  %141 : FloatTensor = onnx::Mul(%140, %distilbert.embeddings.LayerNorm.weight)\n",
      "  %142 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%141, %distilbert.embeddings.LayerNorm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %143 : Tensor = onnx::Shape(%142)\n",
      "  %144 : Tensor = onnx::Constant[value={0}]()\n",
      "  %145 : Long(device=cpu) = onnx::Gather[axis=0](%143, %144) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %146 : Tensor = onnx::Shape(%142)\n",
      "  %147 : Tensor = onnx::Constant[value={1}]()\n",
      "  %148 : Long(device=cpu) = onnx::Gather[axis=0](%146, %147) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %150 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%142, %857) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %151 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%150, %distilbert.transformer.layer.0.attention.q_lin.bias)\n",
      "  %155 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %159 : Tensor = onnx::Concat[axis=0](%155, %858, %859, %860)\n",
      "  %160 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%151, %159) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %161 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%160) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %163 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%142, %861) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %164 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%163, %distilbert.transformer.layer.0.attention.k_lin.bias)\n",
      "  %168 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %172 : Tensor = onnx::Concat[axis=0](%168, %862, %863, %864)\n",
      "  %173 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%164, %172) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %175 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%142, %865) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %176 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%175, %distilbert.transformer.layer.0.attention.v_lin.bias)\n",
      "  %180 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %184 : Tensor = onnx::Concat[axis=0](%180, %866, %867, %868)\n",
      "  %185 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%176, %184) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %186 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%185) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %187 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %188 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%161, %187)\n",
      "  %189 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%173) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %190 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%188, %189) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %191 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %192 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %191) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %195 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %198 : Tensor = onnx::Unsqueeze[axes=[0]](%148)\n",
      "  %199 : Tensor = onnx::Concat[axis=0](%195, %869, %870, %198)\n",
      "  %200 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%192, %199) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %201 : Tensor = onnx::Shape(%190)\n",
      "  %202 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%200, %201) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %203 : Tensor = onnx::Cast[to=9](%202)\n",
      "  %204 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %205 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%203, %204, %190)\n",
      "  %206 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%205) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %207 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%206, %186) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %208 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%207) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %211 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %214 : Tensor = onnx::Concat[axis=0](%211, %871, %872)\n",
      "  %215 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%208, %214) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %217 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%215, %873) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %218 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%217, %distilbert.transformer.layer.0.attention.out_lin.bias)\n",
      "  %219 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%218, %142) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %221 : Tensor = onnx::ReduceMean[axes=[-1]](%219)\n",
      "  %222 : FloatTensor = onnx::Sub(%219, %221)\n",
      "  %223 : Tensor = onnx::Cast[to=1](%222)\n",
      "  %225 : Tensor = onnx::Pow(%223, %874)\n",
      "  %226 : Tensor = onnx::ReduceMean[axes=[-1]](%225)\n",
      "  %227 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %228 : FloatTensor = onnx::Add(%226, %227)\n",
      "  %229 : Tensor = onnx::Sqrt(%228)\n",
      "  %230 : FloatTensor = onnx::Div(%222, %229)\n",
      "  %231 : FloatTensor = onnx::Mul(%230, %distilbert.transformer.layer.0.sa_layer_norm.weight)\n",
      "  %232 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%231, %distilbert.transformer.layer.0.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %234 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%232, %875) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %235 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%234, %distilbert.transformer.layer.0.ffn.lin1.bias)\n",
      "  %236 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %237 : FloatTensor = onnx::Div(%235, %236)\n",
      "  %238 : Tensor = onnx::Erf(%237)\n",
      "  %239 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %240 : FloatTensor = onnx::Add(%238, %239)\n",
      "  %241 : FloatTensor = onnx::Mul(%235, %240)\n",
      "  %242 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %243 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%241, %242) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %245 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%243, %876) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %246 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%245, %distilbert.transformer.layer.0.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %247 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%246, %232) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %249 : Tensor = onnx::ReduceMean[axes=[-1]](%247)\n",
      "  %250 : FloatTensor = onnx::Sub(%247, %249)\n",
      "  %251 : Tensor = onnx::Cast[to=1](%250)\n",
      "  %253 : Tensor = onnx::Pow(%251, %877)\n",
      "  %254 : Tensor = onnx::ReduceMean[axes=[-1]](%253)\n",
      "  %255 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %256 : FloatTensor = onnx::Add(%254, %255)\n",
      "  %257 : Tensor = onnx::Sqrt(%256)\n",
      "  %258 : FloatTensor = onnx::Div(%250, %257)\n",
      "  %259 : FloatTensor = onnx::Mul(%258, %distilbert.transformer.layer.0.output_layer_norm.weight)\n",
      "  %260 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%259, %distilbert.transformer.layer.0.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %261 : Tensor = onnx::Shape(%260)\n",
      "  %262 : Tensor = onnx::Constant[value={0}]()\n",
      "  %263 : Long(device=cpu) = onnx::Gather[axis=0](%261, %262) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %264 : Tensor = onnx::Shape(%260)\n",
      "  %265 : Tensor = onnx::Constant[value={1}]()\n",
      "  %266 : Long(device=cpu) = onnx::Gather[axis=0](%264, %265) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %268 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%260, %878) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %269 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%268, %distilbert.transformer.layer.1.attention.q_lin.bias)\n",
      "  %273 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %277 : Tensor = onnx::Concat[axis=0](%273, %879, %880, %881)\n",
      "  %278 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%269, %277) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %279 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%278) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %281 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%260, %882) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %282 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%281, %distilbert.transformer.layer.1.attention.k_lin.bias)\n",
      "  %286 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %290 : Tensor = onnx::Concat[axis=0](%286, %883, %884, %885)\n",
      "  %291 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%282, %290) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %293 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%260, %886) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %294 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%293, %distilbert.transformer.layer.1.attention.v_lin.bias)\n",
      "  %298 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %302 : Tensor = onnx::Concat[axis=0](%298, %887, %888, %889)\n",
      "  %303 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%294, %302) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %304 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%303) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %305 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %306 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%279, %305)\n",
      "  %307 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%291) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %308 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%306, %307) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %309 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %310 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %309) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %313 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %316 : Tensor = onnx::Unsqueeze[axes=[0]](%266)\n",
      "  %317 : Tensor = onnx::Concat[axis=0](%313, %890, %891, %316)\n",
      "  %318 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%310, %317) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %319 : Tensor = onnx::Shape(%308)\n",
      "  %320 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%318, %319) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %321 : Tensor = onnx::Cast[to=9](%320)\n",
      "  %322 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %323 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%321, %322, %308)\n",
      "  %324 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%323) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %325 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%324, %304) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %326 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%325) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %329 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %332 : Tensor = onnx::Concat[axis=0](%329, %892, %893)\n",
      "  %333 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%326, %332) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %335 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%333, %894) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %336 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%335, %distilbert.transformer.layer.1.attention.out_lin.bias)\n",
      "  %337 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%336, %260) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %339 : Tensor = onnx::ReduceMean[axes=[-1]](%337)\n",
      "  %340 : FloatTensor = onnx::Sub(%337, %339)\n",
      "  %341 : Tensor = onnx::Cast[to=1](%340)\n",
      "  %343 : Tensor = onnx::Pow(%341, %895)\n",
      "  %344 : Tensor = onnx::ReduceMean[axes=[-1]](%343)\n",
      "  %345 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %346 : FloatTensor = onnx::Add(%344, %345)\n",
      "  %347 : Tensor = onnx::Sqrt(%346)\n",
      "  %348 : FloatTensor = onnx::Div(%340, %347)\n",
      "  %349 : FloatTensor = onnx::Mul(%348, %distilbert.transformer.layer.1.sa_layer_norm.weight)\n",
      "  %350 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%349, %distilbert.transformer.layer.1.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %352 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%350, %896) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %353 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%352, %distilbert.transformer.layer.1.ffn.lin1.bias)\n",
      "  %354 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %355 : FloatTensor = onnx::Div(%353, %354)\n",
      "  %356 : Tensor = onnx::Erf(%355)\n",
      "  %357 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %358 : FloatTensor = onnx::Add(%356, %357)\n",
      "  %359 : FloatTensor = onnx::Mul(%353, %358)\n",
      "  %360 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %361 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%359, %360) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %363 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%361, %897) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %364 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%363, %distilbert.transformer.layer.1.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %365 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%364, %350) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %367 : Tensor = onnx::ReduceMean[axes=[-1]](%365)\n",
      "  %368 : FloatTensor = onnx::Sub(%365, %367)\n",
      "  %369 : Tensor = onnx::Cast[to=1](%368)\n",
      "  %371 : Tensor = onnx::Pow(%369, %898)\n",
      "  %372 : Tensor = onnx::ReduceMean[axes=[-1]](%371)\n",
      "  %373 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %374 : FloatTensor = onnx::Add(%372, %373)\n",
      "  %375 : Tensor = onnx::Sqrt(%374)\n",
      "  %376 : FloatTensor = onnx::Div(%368, %375)\n",
      "  %377 : FloatTensor = onnx::Mul(%376, %distilbert.transformer.layer.1.output_layer_norm.weight)\n",
      "  %378 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%377, %distilbert.transformer.layer.1.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %379 : Tensor = onnx::Shape(%378)\n",
      "  %380 : Tensor = onnx::Constant[value={0}]()\n",
      "  %381 : Long(device=cpu) = onnx::Gather[axis=0](%379, %380) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %382 : Tensor = onnx::Shape(%378)\n",
      "  %383 : Tensor = onnx::Constant[value={1}]()\n",
      "  %384 : Long(device=cpu) = onnx::Gather[axis=0](%382, %383) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %386 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%378, %899) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %387 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%386, %distilbert.transformer.layer.2.attention.q_lin.bias)\n",
      "  %391 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %395 : Tensor = onnx::Concat[axis=0](%391, %900, %901, %902)\n",
      "  %396 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%387, %395) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %397 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%396) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %399 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%378, %903) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %400 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%399, %distilbert.transformer.layer.2.attention.k_lin.bias)\n",
      "  %404 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %408 : Tensor = onnx::Concat[axis=0](%404, %904, %905, %906)\n",
      "  %409 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%400, %408) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %411 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%378, %907) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %412 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%411, %distilbert.transformer.layer.2.attention.v_lin.bias)\n",
      "  %416 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %420 : Tensor = onnx::Concat[axis=0](%416, %908, %909, %910)\n",
      "  %421 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%412, %420) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %422 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%421) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %423 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %424 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%397, %423)\n",
      "  %425 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%409) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %426 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%424, %425) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %427 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %428 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %427) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %431 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %434 : Tensor = onnx::Unsqueeze[axes=[0]](%384)\n",
      "  %435 : Tensor = onnx::Concat[axis=0](%431, %911, %912, %434)\n",
      "  %436 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%428, %435) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %437 : Tensor = onnx::Shape(%426)\n",
      "  %438 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%436, %437) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %439 : Tensor = onnx::Cast[to=9](%438)\n",
      "  %440 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %441 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%439, %440, %426)\n",
      "  %442 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%441) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %443 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%442, %422) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %444 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%443) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %447 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %450 : Tensor = onnx::Concat[axis=0](%447, %913, %914)\n",
      "  %451 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%444, %450) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %453 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%451, %915) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %454 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%453, %distilbert.transformer.layer.2.attention.out_lin.bias)\n",
      "  %455 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%454, %378) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %457 : Tensor = onnx::ReduceMean[axes=[-1]](%455)\n",
      "  %458 : FloatTensor = onnx::Sub(%455, %457)\n",
      "  %459 : Tensor = onnx::Cast[to=1](%458)\n",
      "  %461 : Tensor = onnx::Pow(%459, %916)\n",
      "  %462 : Tensor = onnx::ReduceMean[axes=[-1]](%461)\n",
      "  %463 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %464 : FloatTensor = onnx::Add(%462, %463)\n",
      "  %465 : Tensor = onnx::Sqrt(%464)\n",
      "  %466 : FloatTensor = onnx::Div(%458, %465)\n",
      "  %467 : FloatTensor = onnx::Mul(%466, %distilbert.transformer.layer.2.sa_layer_norm.weight)\n",
      "  %468 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%467, %distilbert.transformer.layer.2.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %470 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%468, %917) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %471 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%470, %distilbert.transformer.layer.2.ffn.lin1.bias)\n",
      "  %472 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %473 : FloatTensor = onnx::Div(%471, %472)\n",
      "  %474 : Tensor = onnx::Erf(%473)\n",
      "  %475 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %476 : FloatTensor = onnx::Add(%474, %475)\n",
      "  %477 : FloatTensor = onnx::Mul(%471, %476)\n",
      "  %478 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %479 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%477, %478) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %481 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%479, %918) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %482 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%481, %distilbert.transformer.layer.2.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %483 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%482, %468) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %485 : Tensor = onnx::ReduceMean[axes=[-1]](%483)\n",
      "  %486 : FloatTensor = onnx::Sub(%483, %485)\n",
      "  %487 : Tensor = onnx::Cast[to=1](%486)\n",
      "  %489 : Tensor = onnx::Pow(%487, %919)\n",
      "  %490 : Tensor = onnx::ReduceMean[axes=[-1]](%489)\n",
      "  %491 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %492 : FloatTensor = onnx::Add(%490, %491)\n",
      "  %493 : Tensor = onnx::Sqrt(%492)\n",
      "  %494 : FloatTensor = onnx::Div(%486, %493)\n",
      "  %495 : FloatTensor = onnx::Mul(%494, %distilbert.transformer.layer.2.output_layer_norm.weight)\n",
      "  %496 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%495, %distilbert.transformer.layer.2.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %497 : Tensor = onnx::Shape(%496)\n",
      "  %498 : Tensor = onnx::Constant[value={0}]()\n",
      "  %499 : Long(device=cpu) = onnx::Gather[axis=0](%497, %498) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %500 : Tensor = onnx::Shape(%496)\n",
      "  %501 : Tensor = onnx::Constant[value={1}]()\n",
      "  %502 : Long(device=cpu) = onnx::Gather[axis=0](%500, %501) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %504 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%496, %920) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %505 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%504, %distilbert.transformer.layer.3.attention.q_lin.bias)\n",
      "  %509 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %513 : Tensor = onnx::Concat[axis=0](%509, %921, %922, %923)\n",
      "  %514 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%505, %513) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %515 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%514) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %517 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%496, %924) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %518 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%517, %distilbert.transformer.layer.3.attention.k_lin.bias)\n",
      "  %522 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %526 : Tensor = onnx::Concat[axis=0](%522, %925, %926, %927)\n",
      "  %527 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%518, %526) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %529 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%496, %928) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %530 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%529, %distilbert.transformer.layer.3.attention.v_lin.bias)\n",
      "  %534 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %538 : Tensor = onnx::Concat[axis=0](%534, %929, %930, %931)\n",
      "  %539 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%530, %538) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %540 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%539) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %541 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %542 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%515, %541)\n",
      "  %543 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%527) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %544 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%542, %543) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %545 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %546 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %545) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %549 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %552 : Tensor = onnx::Unsqueeze[axes=[0]](%502)\n",
      "  %553 : Tensor = onnx::Concat[axis=0](%549, %932, %933, %552)\n",
      "  %554 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%546, %553) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %555 : Tensor = onnx::Shape(%544)\n",
      "  %556 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%554, %555) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %557 : Tensor = onnx::Cast[to=9](%556)\n",
      "  %558 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %559 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%557, %558, %544)\n",
      "  %560 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%559) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %561 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%560, %540) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %562 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%561) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %565 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %568 : Tensor = onnx::Concat[axis=0](%565, %934, %935)\n",
      "  %569 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%562, %568) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %571 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%569, %936) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %572 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%571, %distilbert.transformer.layer.3.attention.out_lin.bias)\n",
      "  %573 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%572, %496) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %575 : Tensor = onnx::ReduceMean[axes=[-1]](%573)\n",
      "  %576 : FloatTensor = onnx::Sub(%573, %575)\n",
      "  %577 : Tensor = onnx::Cast[to=1](%576)\n",
      "  %579 : Tensor = onnx::Pow(%577, %937)\n",
      "  %580 : Tensor = onnx::ReduceMean[axes=[-1]](%579)\n",
      "  %581 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %582 : FloatTensor = onnx::Add(%580, %581)\n",
      "  %583 : Tensor = onnx::Sqrt(%582)\n",
      "  %584 : FloatTensor = onnx::Div(%576, %583)\n",
      "  %585 : FloatTensor = onnx::Mul(%584, %distilbert.transformer.layer.3.sa_layer_norm.weight)\n",
      "  %586 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%585, %distilbert.transformer.layer.3.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %588 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%586, %938) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %589 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%588, %distilbert.transformer.layer.3.ffn.lin1.bias)\n",
      "  %590 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %591 : FloatTensor = onnx::Div(%589, %590)\n",
      "  %592 : Tensor = onnx::Erf(%591)\n",
      "  %593 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %594 : FloatTensor = onnx::Add(%592, %593)\n",
      "  %595 : FloatTensor = onnx::Mul(%589, %594)\n",
      "  %596 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %597 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%595, %596) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %599 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%597, %939) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %600 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%599, %distilbert.transformer.layer.3.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %601 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%600, %586) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %603 : Tensor = onnx::ReduceMean[axes=[-1]](%601)\n",
      "  %604 : FloatTensor = onnx::Sub(%601, %603)\n",
      "  %605 : Tensor = onnx::Cast[to=1](%604)\n",
      "  %607 : Tensor = onnx::Pow(%605, %940)\n",
      "  %608 : Tensor = onnx::ReduceMean[axes=[-1]](%607)\n",
      "  %609 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %610 : FloatTensor = onnx::Add(%608, %609)\n",
      "  %611 : Tensor = onnx::Sqrt(%610)\n",
      "  %612 : FloatTensor = onnx::Div(%604, %611)\n",
      "  %613 : FloatTensor = onnx::Mul(%612, %distilbert.transformer.layer.3.output_layer_norm.weight)\n",
      "  %614 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%613, %distilbert.transformer.layer.3.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %615 : Tensor = onnx::Shape(%614)\n",
      "  %616 : Tensor = onnx::Constant[value={0}]()\n",
      "  %617 : Long(device=cpu) = onnx::Gather[axis=0](%615, %616) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %618 : Tensor = onnx::Shape(%614)\n",
      "  %619 : Tensor = onnx::Constant[value={1}]()\n",
      "  %620 : Long(device=cpu) = onnx::Gather[axis=0](%618, %619) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %622 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%614, %941) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %623 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%622, %distilbert.transformer.layer.4.attention.q_lin.bias)\n",
      "  %627 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %631 : Tensor = onnx::Concat[axis=0](%627, %942, %943, %944)\n",
      "  %632 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%623, %631) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %633 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%632) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %635 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%614, %945) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %636 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%635, %distilbert.transformer.layer.4.attention.k_lin.bias)\n",
      "  %640 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %644 : Tensor = onnx::Concat[axis=0](%640, %946, %947, %948)\n",
      "  %645 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%636, %644) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %647 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%614, %949) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %648 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%647, %distilbert.transformer.layer.4.attention.v_lin.bias)\n",
      "  %652 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %656 : Tensor = onnx::Concat[axis=0](%652, %950, %951, %952)\n",
      "  %657 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%648, %656) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %658 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%657) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %659 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %660 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%633, %659)\n",
      "  %661 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%645) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %662 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%660, %661) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %663 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %664 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %663) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %667 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %670 : Tensor = onnx::Unsqueeze[axes=[0]](%620)\n",
      "  %671 : Tensor = onnx::Concat[axis=0](%667, %953, %954, %670)\n",
      "  %672 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%664, %671) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %673 : Tensor = onnx::Shape(%662)\n",
      "  %674 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%672, %673) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %675 : Tensor = onnx::Cast[to=9](%674)\n",
      "  %676 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %677 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%675, %676, %662)\n",
      "  %678 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%677) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %679 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%678, %658) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %680 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%679) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %683 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %686 : Tensor = onnx::Concat[axis=0](%683, %955, %956)\n",
      "  %687 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%680, %686) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %689 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%687, %957) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %690 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%689, %distilbert.transformer.layer.4.attention.out_lin.bias)\n",
      "  %691 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%690, %614) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %693 : Tensor = onnx::ReduceMean[axes=[-1]](%691)\n",
      "  %694 : FloatTensor = onnx::Sub(%691, %693)\n",
      "  %695 : Tensor = onnx::Cast[to=1](%694)\n",
      "  %697 : Tensor = onnx::Pow(%695, %958)\n",
      "  %698 : Tensor = onnx::ReduceMean[axes=[-1]](%697)\n",
      "  %699 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %700 : FloatTensor = onnx::Add(%698, %699)\n",
      "  %701 : Tensor = onnx::Sqrt(%700)\n",
      "  %702 : FloatTensor = onnx::Div(%694, %701)\n",
      "  %703 : FloatTensor = onnx::Mul(%702, %distilbert.transformer.layer.4.sa_layer_norm.weight)\n",
      "  %704 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%703, %distilbert.transformer.layer.4.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %706 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%704, %959) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %707 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%706, %distilbert.transformer.layer.4.ffn.lin1.bias)\n",
      "  %708 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %709 : FloatTensor = onnx::Div(%707, %708)\n",
      "  %710 : Tensor = onnx::Erf(%709)\n",
      "  %711 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %712 : FloatTensor = onnx::Add(%710, %711)\n",
      "  %713 : FloatTensor = onnx::Mul(%707, %712)\n",
      "  %714 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %715 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%713, %714) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %717 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%715, %960) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %718 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%717, %distilbert.transformer.layer.4.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %719 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%718, %704) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %721 : Tensor = onnx::ReduceMean[axes=[-1]](%719)\n",
      "  %722 : FloatTensor = onnx::Sub(%719, %721)\n",
      "  %723 : Tensor = onnx::Cast[to=1](%722)\n",
      "  %725 : Tensor = onnx::Pow(%723, %961)\n",
      "  %726 : Tensor = onnx::ReduceMean[axes=[-1]](%725)\n",
      "  %727 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %728 : FloatTensor = onnx::Add(%726, %727)\n",
      "  %729 : Tensor = onnx::Sqrt(%728)\n",
      "  %730 : FloatTensor = onnx::Div(%722, %729)\n",
      "  %731 : FloatTensor = onnx::Mul(%730, %distilbert.transformer.layer.4.output_layer_norm.weight)\n",
      "  %732 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%731, %distilbert.transformer.layer.4.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %733 : Tensor = onnx::Shape(%732)\n",
      "  %734 : Tensor = onnx::Constant[value={0}]()\n",
      "  %735 : Long(device=cpu) = onnx::Gather[axis=0](%733, %734) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %736 : Tensor = onnx::Shape(%732)\n",
      "  %737 : Tensor = onnx::Constant[value={1}]()\n",
      "  %738 : Long(device=cpu) = onnx::Gather[axis=0](%736, %737) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %740 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%732, %962) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %741 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%740, %distilbert.transformer.layer.5.attention.q_lin.bias)\n",
      "  %745 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %749 : Tensor = onnx::Concat[axis=0](%745, %963, %964, %965)\n",
      "  %750 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%741, %749) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %751 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%750) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %753 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%732, %966) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %754 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%753, %distilbert.transformer.layer.5.attention.k_lin.bias)\n",
      "  %758 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %762 : Tensor = onnx::Concat[axis=0](%758, %967, %968, %969)\n",
      "  %763 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%754, %762) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %765 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%732, %970) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %766 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%765, %distilbert.transformer.layer.5.attention.v_lin.bias)\n",
      "  %770 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %774 : Tensor = onnx::Concat[axis=0](%770, %971, %972, %973)\n",
      "  %775 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%766, %774) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %776 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%775) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %777 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %778 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%751, %777)\n",
      "  %779 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%763) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %780 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%778, %779) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %781 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %782 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %781) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %785 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %788 : Tensor = onnx::Unsqueeze[axes=[0]](%738)\n",
      "  %789 : Tensor = onnx::Concat[axis=0](%785, %974, %975, %788)\n",
      "  %790 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%782, %789) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %791 : Tensor = onnx::Shape(%780)\n",
      "  %792 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%790, %791) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %793 : Tensor = onnx::Cast[to=9](%792)\n",
      "  %794 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %795 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%793, %794, %780)\n",
      "  %796 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%795) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %797 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%796, %776) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %798 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%797) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %801 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %804 : Tensor = onnx::Concat[axis=0](%801, %976, %977)\n",
      "  %805 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%798, %804) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %807 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%805, %978) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %808 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%807, %distilbert.transformer.layer.5.attention.out_lin.bias)\n",
      "  %809 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%808, %732) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %811 : Tensor = onnx::ReduceMean[axes=[-1]](%809)\n",
      "  %812 : FloatTensor = onnx::Sub(%809, %811)\n",
      "  %813 : Tensor = onnx::Cast[to=1](%812)\n",
      "  %815 : Tensor = onnx::Pow(%813, %979)\n",
      "  %816 : Tensor = onnx::ReduceMean[axes=[-1]](%815)\n",
      "  %817 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %818 : FloatTensor = onnx::Add(%816, %817)\n",
      "  %819 : Tensor = onnx::Sqrt(%818)\n",
      "  %820 : FloatTensor = onnx::Div(%812, %819)\n",
      "  %821 : FloatTensor = onnx::Mul(%820, %distilbert.transformer.layer.5.sa_layer_norm.weight)\n",
      "  %822 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%821, %distilbert.transformer.layer.5.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %824 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%822, %980) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %825 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%824, %distilbert.transformer.layer.5.ffn.lin1.bias)\n",
      "  %826 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %827 : FloatTensor = onnx::Div(%825, %826)\n",
      "  %828 : Tensor = onnx::Erf(%827)\n",
      "  %829 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %830 : FloatTensor = onnx::Add(%828, %829)\n",
      "  %831 : FloatTensor = onnx::Mul(%825, %830)\n",
      "  %832 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %833 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%831, %832) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %835 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%833, %981) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %836 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%835, %distilbert.transformer.layer.5.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %837 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%836, %822) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %839 : Tensor = onnx::ReduceMean[axes=[-1]](%837)\n",
      "  %840 : FloatTensor = onnx::Sub(%837, %839)\n",
      "  %841 : Tensor = onnx::Cast[to=1](%840)\n",
      "  %843 : Tensor = onnx::Pow(%841, %982)\n",
      "  %844 : Tensor = onnx::ReduceMean[axes=[-1]](%843)\n",
      "  %845 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %846 : FloatTensor = onnx::Add(%844, %845)\n",
      "  %847 : Tensor = onnx::Sqrt(%846)\n",
      "  %848 : FloatTensor = onnx::Div(%840, %847)\n",
      "  %849 : FloatTensor = onnx::Mul(%848, %distilbert.transformer.layer.5.output_layer_norm.weight)\n",
      "  %850 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%849, %distilbert.transformer.layer.5.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %851 : Tensor = onnx::Constant[value={0}]()\n",
      "  %852 : Float(1:10752, 768:1, requires_grad=1, device=cpu) = onnx::Gather[axis=1](%850, %851) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %853 : Float(1:768, 768:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%852, %pre_classifier.weight, %pre_classifier.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  %854 : Float(1:768, 768:1, requires_grad=1, device=cpu) = onnx::Relu(%853) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %855 : Float(1:2, 2:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%854, %classifier.weight, %classifier.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  return (%855)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "#enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "enc = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "\n",
    "# for deubg\n",
    "print(\"tokenized_text: {}\".format(tokenized_text))\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "dummy_input = tokens_tensor\n",
    "\n",
    "# for deubg\n",
    "# 14 tokens for output\n",
    "print(\"tokens_tensor shape: {}\".format(tokens_tensor.shape))\n",
    "print(\"segments_tensor shape: {}\".format(segments_tensors.shape))\n",
    "\n",
    "print(\"tokens_tensor: {}\".format(tokens_tensor))\n",
    "print(\"segments_tensor: {}\".format(segments_tensors))\n",
    "\n",
    "\n",
    "# Initializing the model with the torchscript flag\n",
    "# Flag set to True even though it is not necessary as this model does not have an LM Head.\n",
    "#config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "#    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, torchscript=True)\n",
    "\n",
    "# Instantiating the model\n",
    "#model = BertModel(config)\n",
    "\n",
    "# The model needs to be in evaluation mode\n",
    "#model.eval()\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "# classfication only  0 and 1 so set ut to 2\n",
    "num_labels = 2\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels,\n",
    "                                                            output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.onnx.export(model, dummy_input, 'traced_distill_bert.onnx', verbose=True)\n",
    "\n",
    "\n",
    "# if want to want to download, uncomment it \n",
    "#torch.jit.save(traced_model, \"traced_distill_bert.pt\")"
   ]
  },
  {
   "source": [
    "#remove torchscript\n",
    "# change to distillation bert\n",
    "#output to onnx\n",
    "# gpu version\n",
    "# https://github.com/huggingface/transformers/issues/227\n",
    "#https://huggingface.co/transformers/serialization.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenized_text: ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
      "indexed_tokens: [101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 13997, 11510, 102]\n",
      "create input for device: cpu\n",
      "tokens_tensor shape for chunk: 14\n",
      "token_tensor shape for chunk: 14\n",
      "tokens_tensor shape: torch.Size([1, 14])\n",
      "segments_tensor shape: torch.Size([1, 1])\n",
      "tokens_tensor: tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]])\n",
      "segments_tensor: tensor([[0]])\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "graph(%input.1 : Long(1:14, 14:1, requires_grad=0, device=cpu),\n",
      "      %distilbert.embeddings.word_embeddings.weight : Float(30522:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.embeddings.position_embeddings.weight : Float(512:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.embeddings.LayerNorm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.embeddings.LayerNorm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.0.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.1.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.2.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.3.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.4.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.q_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.k_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.v_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.attention.out_lin.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.sa_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.sa_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.ffn.lin1.bias : Float(3072:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.ffn.lin2.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.output_layer_norm.weight : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %distilbert.transformer.layer.5.output_layer_norm.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %pre_classifier.weight : Float(768:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %pre_classifier.bias : Float(768:1, requires_grad=1, device=cpu),\n",
      "      %classifier.weight : Float(2:768, 768:1, requires_grad=1, device=cpu),\n",
      "      %classifier.bias : Float(2:1, requires_grad=1, device=cpu),\n",
      "      %856 : Float(requires_grad=0, device=cpu),\n",
      "      %857 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %858 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %859 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %860 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %861 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %862 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %863 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %864 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %865 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %866 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %867 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %868 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %869 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %870 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %871 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %872 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %873 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %874 : Float(requires_grad=0, device=cpu),\n",
      "      %875 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %876 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %877 : Float(requires_grad=0, device=cpu),\n",
      "      %878 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %879 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %880 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %881 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %882 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %883 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %884 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %885 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %886 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %887 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %888 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %889 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %890 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %891 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %892 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %893 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %894 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %895 : Float(requires_grad=0, device=cpu),\n",
      "      %896 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %897 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %898 : Float(requires_grad=0, device=cpu),\n",
      "      %899 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %900 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %901 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %902 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %903 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %904 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %905 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %906 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %907 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %908 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %909 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %910 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %911 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %912 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %913 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %914 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %915 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %916 : Float(requires_grad=0, device=cpu),\n",
      "      %917 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %918 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %919 : Float(requires_grad=0, device=cpu),\n",
      "      %920 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %921 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %922 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %923 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %924 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %925 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %926 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %927 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %928 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %929 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %930 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %931 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %932 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %933 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %934 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %935 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %936 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %937 : Float(requires_grad=0, device=cpu),\n",
      "      %938 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %939 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %940 : Float(requires_grad=0, device=cpu),\n",
      "      %941 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %942 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %943 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %944 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %945 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %946 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %947 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %948 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %949 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %950 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %951 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %952 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %953 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %954 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %955 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %956 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %957 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %958 : Float(requires_grad=0, device=cpu),\n",
      "      %959 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %960 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %961 : Float(requires_grad=0, device=cpu),\n",
      "      %962 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %963 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %964 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %965 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %966 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %967 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %968 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %969 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %970 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %971 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %972 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %973 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %974 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %975 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %976 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %977 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %978 : Float(768:1, 768:768, requires_grad=0, device=cpu),\n",
      "      %979 : Float(requires_grad=0, device=cpu),\n",
      "      %980 : Float(768:1, 3072:768, requires_grad=0, device=cpu),\n",
      "      %981 : Float(3072:1, 768:3072, requires_grad=0, device=cpu),\n",
      "      %982 : Float(requires_grad=0, device=cpu)):\n",
      "  %105 : Tensor = onnx::Shape(%input.1)\n",
      "  %106 : Tensor = onnx::Constant[value={0}]()\n",
      "  %107 : Long(device=cpu) = onnx::Gather[axis=0](%105, %106) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:483:0\n",
      "  %108 : Tensor = onnx::Shape(%input.1)\n",
      "  %109 : Tensor = onnx::Constant[value={1}]()\n",
      "  %110 : Long(device=cpu) = onnx::Gather[axis=0](%108, %109) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:483:0\n",
      "  %111 : Tensor = onnx::Unsqueeze[axes=[0]](%107)\n",
      "  %112 : Tensor = onnx::Unsqueeze[axes=[0]](%110)\n",
      "  %113 : Tensor = onnx::Concat[axis=0](%111, %112)\n",
      "  %114 : Float(1:14, 14:1, requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={1}](%113) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:492:0\n",
      "  %115 : Tensor = onnx::Shape(%input.1)\n",
      "  %116 : Tensor = onnx::Constant[value={1}]()\n",
      "  %117 : Long(device=cpu) = onnx::Gather[axis=0](%115, %116) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:108:0\n",
      "  %118 : Tensor = onnx::Unsqueeze[axes=[0]](%117)\n",
      "  %119 : Tensor = onnx::ConstantOfShape[value={1}](%118)\n",
      "  %120 : Tensor = onnx::NonZero(%119)\n",
      "  %121 : Tensor = onnx::Transpose[perm=[1, 0]](%120)\n",
      "  %122 : Tensor = onnx::Squeeze[axes=[1]](%121)\n",
      "  %123 : Long(14:1, requires_grad=0, device=cpu) = onnx::Cast[to=7](%122) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:109:0\n",
      "  %124 : Long(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[0]](%123) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:110:0\n",
      "  %125 : Tensor = onnx::Shape(%input.1)\n",
      "  %126 : Long(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%124, %125) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:110:0\n",
      "  %127 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Gather(%distilbert.embeddings.word_embeddings.weight, %input.1) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1852:0\n",
      "  %128 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Gather(%distilbert.embeddings.position_embeddings.weight, %126) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1852:0\n",
      "  %129 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%127, %128) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:115:0\n",
      "  %131 : Tensor = onnx::ReduceMean[axes=[-1]](%129)\n",
      "  %132 : FloatTensor = onnx::Sub(%129, %131)\n",
      "  %133 : Tensor = onnx::Cast[to=1](%132)\n",
      "  %135 : Tensor = onnx::Pow(%133, %856)\n",
      "  %136 : Tensor = onnx::ReduceMean[axes=[-1]](%135)\n",
      "  %137 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %138 : FloatTensor = onnx::Add(%136, %137)\n",
      "  %139 : Tensor = onnx::Sqrt(%138)\n",
      "  %140 : FloatTensor = onnx::Div(%132, %139)\n",
      "  %141 : FloatTensor = onnx::Mul(%140, %distilbert.embeddings.LayerNorm.weight)\n",
      "  %142 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%141, %distilbert.embeddings.LayerNorm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %143 : Tensor = onnx::Shape(%142)\n",
      "  %144 : Tensor = onnx::Constant[value={0}]()\n",
      "  %145 : Long(device=cpu) = onnx::Gather[axis=0](%143, %144) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %146 : Tensor = onnx::Shape(%142)\n",
      "  %147 : Tensor = onnx::Constant[value={1}]()\n",
      "  %148 : Long(device=cpu) = onnx::Gather[axis=0](%146, %147) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %150 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%142, %857) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %151 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%150, %distilbert.transformer.layer.0.attention.q_lin.bias)\n",
      "  %155 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %159 : Tensor = onnx::Concat[axis=0](%155, %858, %859, %860)\n",
      "  %160 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%151, %159) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %161 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%160) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %163 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%142, %861) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %164 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%163, %distilbert.transformer.layer.0.attention.k_lin.bias)\n",
      "  %168 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %172 : Tensor = onnx::Concat[axis=0](%168, %862, %863, %864)\n",
      "  %173 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%164, %172) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %175 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%142, %865) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %176 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%175, %distilbert.transformer.layer.0.attention.v_lin.bias)\n",
      "  %180 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %184 : Tensor = onnx::Concat[axis=0](%180, %866, %867, %868)\n",
      "  %185 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%176, %184) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %186 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%185) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %187 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %188 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%161, %187)\n",
      "  %189 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%173) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %190 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%188, %189) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %191 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %192 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %191) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %195 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %198 : Tensor = onnx::Unsqueeze[axes=[0]](%148)\n",
      "  %199 : Tensor = onnx::Concat[axis=0](%195, %869, %870, %198)\n",
      "  %200 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%192, %199) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %201 : Tensor = onnx::Shape(%190)\n",
      "  %202 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%200, %201) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %203 : Tensor = onnx::Cast[to=9](%202)\n",
      "  %204 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %205 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%203, %204, %190)\n",
      "  %206 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%205) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %207 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%206, %186) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %208 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%207) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %211 : Tensor = onnx::Unsqueeze[axes=[0]](%145)\n",
      "  %214 : Tensor = onnx::Concat[axis=0](%211, %871, %872)\n",
      "  %215 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%208, %214) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %217 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%215, %873) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %218 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%217, %distilbert.transformer.layer.0.attention.out_lin.bias)\n",
      "  %219 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%218, %142) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %221 : Tensor = onnx::ReduceMean[axes=[-1]](%219)\n",
      "  %222 : FloatTensor = onnx::Sub(%219, %221)\n",
      "  %223 : Tensor = onnx::Cast[to=1](%222)\n",
      "  %225 : Tensor = onnx::Pow(%223, %874)\n",
      "  %226 : Tensor = onnx::ReduceMean[axes=[-1]](%225)\n",
      "  %227 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %228 : FloatTensor = onnx::Add(%226, %227)\n",
      "  %229 : Tensor = onnx::Sqrt(%228)\n",
      "  %230 : FloatTensor = onnx::Div(%222, %229)\n",
      "  %231 : FloatTensor = onnx::Mul(%230, %distilbert.transformer.layer.0.sa_layer_norm.weight)\n",
      "  %232 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%231, %distilbert.transformer.layer.0.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %234 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%232, %875) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %235 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%234, %distilbert.transformer.layer.0.ffn.lin1.bias)\n",
      "  %236 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %237 : FloatTensor = onnx::Div(%235, %236)\n",
      "  %238 : Tensor = onnx::Erf(%237)\n",
      "  %239 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %240 : FloatTensor = onnx::Add(%238, %239)\n",
      "  %241 : FloatTensor = onnx::Mul(%235, %240)\n",
      "  %242 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %243 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%241, %242) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %245 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%243, %876) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %246 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%245, %distilbert.transformer.layer.0.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %247 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%246, %232) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %249 : Tensor = onnx::ReduceMean[axes=[-1]](%247)\n",
      "  %250 : FloatTensor = onnx::Sub(%247, %249)\n",
      "  %251 : Tensor = onnx::Cast[to=1](%250)\n",
      "  %253 : Tensor = onnx::Pow(%251, %877)\n",
      "  %254 : Tensor = onnx::ReduceMean[axes=[-1]](%253)\n",
      "  %255 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %256 : FloatTensor = onnx::Add(%254, %255)\n",
      "  %257 : Tensor = onnx::Sqrt(%256)\n",
      "  %258 : FloatTensor = onnx::Div(%250, %257)\n",
      "  %259 : FloatTensor = onnx::Mul(%258, %distilbert.transformer.layer.0.output_layer_norm.weight)\n",
      "  %260 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%259, %distilbert.transformer.layer.0.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %261 : Tensor = onnx::Shape(%260)\n",
      "  %262 : Tensor = onnx::Constant[value={0}]()\n",
      "  %263 : Long(device=cpu) = onnx::Gather[axis=0](%261, %262) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %264 : Tensor = onnx::Shape(%260)\n",
      "  %265 : Tensor = onnx::Constant[value={1}]()\n",
      "  %266 : Long(device=cpu) = onnx::Gather[axis=0](%264, %265) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %268 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%260, %878) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %269 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%268, %distilbert.transformer.layer.1.attention.q_lin.bias)\n",
      "  %273 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %277 : Tensor = onnx::Concat[axis=0](%273, %879, %880, %881)\n",
      "  %278 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%269, %277) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %279 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%278) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %281 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%260, %882) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %282 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%281, %distilbert.transformer.layer.1.attention.k_lin.bias)\n",
      "  %286 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %290 : Tensor = onnx::Concat[axis=0](%286, %883, %884, %885)\n",
      "  %291 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%282, %290) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %293 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%260, %886) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %294 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%293, %distilbert.transformer.layer.1.attention.v_lin.bias)\n",
      "  %298 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %302 : Tensor = onnx::Concat[axis=0](%298, %887, %888, %889)\n",
      "  %303 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%294, %302) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %304 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%303) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %305 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %306 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%279, %305)\n",
      "  %307 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%291) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %308 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%306, %307) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %309 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %310 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %309) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %313 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %316 : Tensor = onnx::Unsqueeze[axes=[0]](%266)\n",
      "  %317 : Tensor = onnx::Concat[axis=0](%313, %890, %891, %316)\n",
      "  %318 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%310, %317) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %319 : Tensor = onnx::Shape(%308)\n",
      "  %320 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%318, %319) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %321 : Tensor = onnx::Cast[to=9](%320)\n",
      "  %322 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %323 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%321, %322, %308)\n",
      "  %324 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%323) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %325 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%324, %304) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %326 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%325) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %329 : Tensor = onnx::Unsqueeze[axes=[0]](%263)\n",
      "  %332 : Tensor = onnx::Concat[axis=0](%329, %892, %893)\n",
      "  %333 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%326, %332) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %335 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%333, %894) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %336 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%335, %distilbert.transformer.layer.1.attention.out_lin.bias)\n",
      "  %337 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%336, %260) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %339 : Tensor = onnx::ReduceMean[axes=[-1]](%337)\n",
      "  %340 : FloatTensor = onnx::Sub(%337, %339)\n",
      "  %341 : Tensor = onnx::Cast[to=1](%340)\n",
      "  %343 : Tensor = onnx::Pow(%341, %895)\n",
      "  %344 : Tensor = onnx::ReduceMean[axes=[-1]](%343)\n",
      "  %345 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %346 : FloatTensor = onnx::Add(%344, %345)\n",
      "  %347 : Tensor = onnx::Sqrt(%346)\n",
      "  %348 : FloatTensor = onnx::Div(%340, %347)\n",
      "  %349 : FloatTensor = onnx::Mul(%348, %distilbert.transformer.layer.1.sa_layer_norm.weight)\n",
      "  %350 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%349, %distilbert.transformer.layer.1.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %352 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%350, %896) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %353 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%352, %distilbert.transformer.layer.1.ffn.lin1.bias)\n",
      "  %354 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %355 : FloatTensor = onnx::Div(%353, %354)\n",
      "  %356 : Tensor = onnx::Erf(%355)\n",
      "  %357 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %358 : FloatTensor = onnx::Add(%356, %357)\n",
      "  %359 : FloatTensor = onnx::Mul(%353, %358)\n",
      "  %360 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %361 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%359, %360) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %363 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%361, %897) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %364 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%363, %distilbert.transformer.layer.1.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %365 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%364, %350) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %367 : Tensor = onnx::ReduceMean[axes=[-1]](%365)\n",
      "  %368 : FloatTensor = onnx::Sub(%365, %367)\n",
      "  %369 : Tensor = onnx::Cast[to=1](%368)\n",
      "  %371 : Tensor = onnx::Pow(%369, %898)\n",
      "  %372 : Tensor = onnx::ReduceMean[axes=[-1]](%371)\n",
      "  %373 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %374 : FloatTensor = onnx::Add(%372, %373)\n",
      "  %375 : Tensor = onnx::Sqrt(%374)\n",
      "  %376 : FloatTensor = onnx::Div(%368, %375)\n",
      "  %377 : FloatTensor = onnx::Mul(%376, %distilbert.transformer.layer.1.output_layer_norm.weight)\n",
      "  %378 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%377, %distilbert.transformer.layer.1.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %379 : Tensor = onnx::Shape(%378)\n",
      "  %380 : Tensor = onnx::Constant[value={0}]()\n",
      "  %381 : Long(device=cpu) = onnx::Gather[axis=0](%379, %380) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %382 : Tensor = onnx::Shape(%378)\n",
      "  %383 : Tensor = onnx::Constant[value={1}]()\n",
      "  %384 : Long(device=cpu) = onnx::Gather[axis=0](%382, %383) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %386 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%378, %899) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %387 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%386, %distilbert.transformer.layer.2.attention.q_lin.bias)\n",
      "  %391 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %395 : Tensor = onnx::Concat[axis=0](%391, %900, %901, %902)\n",
      "  %396 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%387, %395) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %397 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%396) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %399 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%378, %903) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %400 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%399, %distilbert.transformer.layer.2.attention.k_lin.bias)\n",
      "  %404 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %408 : Tensor = onnx::Concat[axis=0](%404, %904, %905, %906)\n",
      "  %409 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%400, %408) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %411 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%378, %907) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %412 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%411, %distilbert.transformer.layer.2.attention.v_lin.bias)\n",
      "  %416 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %420 : Tensor = onnx::Concat[axis=0](%416, %908, %909, %910)\n",
      "  %421 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%412, %420) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %422 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%421) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %423 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %424 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%397, %423)\n",
      "  %425 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%409) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %426 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%424, %425) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %427 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %428 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %427) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %431 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %434 : Tensor = onnx::Unsqueeze[axes=[0]](%384)\n",
      "  %435 : Tensor = onnx::Concat[axis=0](%431, %911, %912, %434)\n",
      "  %436 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%428, %435) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %437 : Tensor = onnx::Shape(%426)\n",
      "  %438 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%436, %437) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %439 : Tensor = onnx::Cast[to=9](%438)\n",
      "  %440 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %441 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%439, %440, %426)\n",
      "  %442 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%441) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %443 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%442, %422) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %444 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%443) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %447 : Tensor = onnx::Unsqueeze[axes=[0]](%381)\n",
      "  %450 : Tensor = onnx::Concat[axis=0](%447, %913, %914)\n",
      "  %451 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%444, %450) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %453 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%451, %915) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %454 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%453, %distilbert.transformer.layer.2.attention.out_lin.bias)\n",
      "  %455 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%454, %378) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %457 : Tensor = onnx::ReduceMean[axes=[-1]](%455)\n",
      "  %458 : FloatTensor = onnx::Sub(%455, %457)\n",
      "  %459 : Tensor = onnx::Cast[to=1](%458)\n",
      "  %461 : Tensor = onnx::Pow(%459, %916)\n",
      "  %462 : Tensor = onnx::ReduceMean[axes=[-1]](%461)\n",
      "  %463 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %464 : FloatTensor = onnx::Add(%462, %463)\n",
      "  %465 : Tensor = onnx::Sqrt(%464)\n",
      "  %466 : FloatTensor = onnx::Div(%458, %465)\n",
      "  %467 : FloatTensor = onnx::Mul(%466, %distilbert.transformer.layer.2.sa_layer_norm.weight)\n",
      "  %468 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%467, %distilbert.transformer.layer.2.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %470 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%468, %917) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %471 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%470, %distilbert.transformer.layer.2.ffn.lin1.bias)\n",
      "  %472 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %473 : FloatTensor = onnx::Div(%471, %472)\n",
      "  %474 : Tensor = onnx::Erf(%473)\n",
      "  %475 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %476 : FloatTensor = onnx::Add(%474, %475)\n",
      "  %477 : FloatTensor = onnx::Mul(%471, %476)\n",
      "  %478 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %479 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%477, %478) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %481 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%479, %918) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %482 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%481, %distilbert.transformer.layer.2.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %483 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%482, %468) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %485 : Tensor = onnx::ReduceMean[axes=[-1]](%483)\n",
      "  %486 : FloatTensor = onnx::Sub(%483, %485)\n",
      "  %487 : Tensor = onnx::Cast[to=1](%486)\n",
      "  %489 : Tensor = onnx::Pow(%487, %919)\n",
      "  %490 : Tensor = onnx::ReduceMean[axes=[-1]](%489)\n",
      "  %491 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %492 : FloatTensor = onnx::Add(%490, %491)\n",
      "  %493 : Tensor = onnx::Sqrt(%492)\n",
      "  %494 : FloatTensor = onnx::Div(%486, %493)\n",
      "  %495 : FloatTensor = onnx::Mul(%494, %distilbert.transformer.layer.2.output_layer_norm.weight)\n",
      "  %496 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%495, %distilbert.transformer.layer.2.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %497 : Tensor = onnx::Shape(%496)\n",
      "  %498 : Tensor = onnx::Constant[value={0}]()\n",
      "  %499 : Long(device=cpu) = onnx::Gather[axis=0](%497, %498) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %500 : Tensor = onnx::Shape(%496)\n",
      "  %501 : Tensor = onnx::Constant[value={1}]()\n",
      "  %502 : Long(device=cpu) = onnx::Gather[axis=0](%500, %501) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %504 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%496, %920) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %505 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%504, %distilbert.transformer.layer.3.attention.q_lin.bias)\n",
      "  %509 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %513 : Tensor = onnx::Concat[axis=0](%509, %921, %922, %923)\n",
      "  %514 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%505, %513) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %515 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%514) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %517 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%496, %924) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %518 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%517, %distilbert.transformer.layer.3.attention.k_lin.bias)\n",
      "  %522 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %526 : Tensor = onnx::Concat[axis=0](%522, %925, %926, %927)\n",
      "  %527 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%518, %526) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %529 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%496, %928) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %530 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%529, %distilbert.transformer.layer.3.attention.v_lin.bias)\n",
      "  %534 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %538 : Tensor = onnx::Concat[axis=0](%534, %929, %930, %931)\n",
      "  %539 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%530, %538) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %540 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%539) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %541 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %542 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%515, %541)\n",
      "  %543 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%527) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %544 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%542, %543) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %545 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %546 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %545) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %549 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %552 : Tensor = onnx::Unsqueeze[axes=[0]](%502)\n",
      "  %553 : Tensor = onnx::Concat[axis=0](%549, %932, %933, %552)\n",
      "  %554 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%546, %553) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %555 : Tensor = onnx::Shape(%544)\n",
      "  %556 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%554, %555) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %557 : Tensor = onnx::Cast[to=9](%556)\n",
      "  %558 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %559 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%557, %558, %544)\n",
      "  %560 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%559) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %561 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%560, %540) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %562 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%561) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %565 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %568 : Tensor = onnx::Concat[axis=0](%565, %934, %935)\n",
      "  %569 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%562, %568) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %571 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%569, %936) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %572 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%571, %distilbert.transformer.layer.3.attention.out_lin.bias)\n",
      "  %573 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%572, %496) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %575 : Tensor = onnx::ReduceMean[axes=[-1]](%573)\n",
      "  %576 : FloatTensor = onnx::Sub(%573, %575)\n",
      "  %577 : Tensor = onnx::Cast[to=1](%576)\n",
      "  %579 : Tensor = onnx::Pow(%577, %937)\n",
      "  %580 : Tensor = onnx::ReduceMean[axes=[-1]](%579)\n",
      "  %581 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %582 : FloatTensor = onnx::Add(%580, %581)\n",
      "  %583 : Tensor = onnx::Sqrt(%582)\n",
      "  %584 : FloatTensor = onnx::Div(%576, %583)\n",
      "  %585 : FloatTensor = onnx::Mul(%584, %distilbert.transformer.layer.3.sa_layer_norm.weight)\n",
      "  %586 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%585, %distilbert.transformer.layer.3.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %588 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%586, %938) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %589 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%588, %distilbert.transformer.layer.3.ffn.lin1.bias)\n",
      "  %590 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %591 : FloatTensor = onnx::Div(%589, %590)\n",
      "  %592 : Tensor = onnx::Erf(%591)\n",
      "  %593 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %594 : FloatTensor = onnx::Add(%592, %593)\n",
      "  %595 : FloatTensor = onnx::Mul(%589, %594)\n",
      "  %596 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %597 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%595, %596) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %599 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%597, %939) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %600 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%599, %distilbert.transformer.layer.3.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %601 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%600, %586) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %603 : Tensor = onnx::ReduceMean[axes=[-1]](%601)\n",
      "  %604 : FloatTensor = onnx::Sub(%601, %603)\n",
      "  %605 : Tensor = onnx::Cast[to=1](%604)\n",
      "  %607 : Tensor = onnx::Pow(%605, %940)\n",
      "  %608 : Tensor = onnx::ReduceMean[axes=[-1]](%607)\n",
      "  %609 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %610 : FloatTensor = onnx::Add(%608, %609)\n",
      "  %611 : Tensor = onnx::Sqrt(%610)\n",
      "  %612 : FloatTensor = onnx::Div(%604, %611)\n",
      "  %613 : FloatTensor = onnx::Mul(%612, %distilbert.transformer.layer.3.output_layer_norm.weight)\n",
      "  %614 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%613, %distilbert.transformer.layer.3.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %615 : Tensor = onnx::Shape(%614)\n",
      "  %616 : Tensor = onnx::Constant[value={0}]()\n",
      "  %617 : Long(device=cpu) = onnx::Gather[axis=0](%615, %616) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %618 : Tensor = onnx::Shape(%614)\n",
      "  %619 : Tensor = onnx::Constant[value={1}]()\n",
      "  %620 : Long(device=cpu) = onnx::Gather[axis=0](%618, %619) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %622 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%614, %941) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %623 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%622, %distilbert.transformer.layer.4.attention.q_lin.bias)\n",
      "  %627 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %631 : Tensor = onnx::Concat[axis=0](%627, %942, %943, %944)\n",
      "  %632 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%623, %631) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %633 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%632) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %635 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%614, %945) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %636 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%635, %distilbert.transformer.layer.4.attention.k_lin.bias)\n",
      "  %640 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %644 : Tensor = onnx::Concat[axis=0](%640, %946, %947, %948)\n",
      "  %645 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%636, %644) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %647 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%614, %949) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %648 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%647, %distilbert.transformer.layer.4.attention.v_lin.bias)\n",
      "  %652 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %656 : Tensor = onnx::Concat[axis=0](%652, %950, %951, %952)\n",
      "  %657 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%648, %656) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %658 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%657) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %659 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %660 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%633, %659)\n",
      "  %661 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%645) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %662 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%660, %661) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %663 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %664 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %663) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %667 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %670 : Tensor = onnx::Unsqueeze[axes=[0]](%620)\n",
      "  %671 : Tensor = onnx::Concat[axis=0](%667, %953, %954, %670)\n",
      "  %672 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%664, %671) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %673 : Tensor = onnx::Shape(%662)\n",
      "  %674 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%672, %673) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %675 : Tensor = onnx::Cast[to=9](%674)\n",
      "  %676 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %677 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%675, %676, %662)\n",
      "  %678 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%677) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %679 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%678, %658) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %680 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%679) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %683 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %686 : Tensor = onnx::Concat[axis=0](%683, %955, %956)\n",
      "  %687 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%680, %686) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %689 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%687, %957) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %690 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%689, %distilbert.transformer.layer.4.attention.out_lin.bias)\n",
      "  %691 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%690, %614) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %693 : Tensor = onnx::ReduceMean[axes=[-1]](%691)\n",
      "  %694 : FloatTensor = onnx::Sub(%691, %693)\n",
      "  %695 : Tensor = onnx::Cast[to=1](%694)\n",
      "  %697 : Tensor = onnx::Pow(%695, %958)\n",
      "  %698 : Tensor = onnx::ReduceMean[axes=[-1]](%697)\n",
      "  %699 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %700 : FloatTensor = onnx::Add(%698, %699)\n",
      "  %701 : Tensor = onnx::Sqrt(%700)\n",
      "  %702 : FloatTensor = onnx::Div(%694, %701)\n",
      "  %703 : FloatTensor = onnx::Mul(%702, %distilbert.transformer.layer.4.sa_layer_norm.weight)\n",
      "  %704 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%703, %distilbert.transformer.layer.4.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %706 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%704, %959) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %707 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%706, %distilbert.transformer.layer.4.ffn.lin1.bias)\n",
      "  %708 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %709 : FloatTensor = onnx::Div(%707, %708)\n",
      "  %710 : Tensor = onnx::Erf(%709)\n",
      "  %711 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %712 : FloatTensor = onnx::Add(%710, %711)\n",
      "  %713 : FloatTensor = onnx::Mul(%707, %712)\n",
      "  %714 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %715 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%713, %714) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %717 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%715, %960) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %718 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%717, %distilbert.transformer.layer.4.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %719 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%718, %704) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %721 : Tensor = onnx::ReduceMean[axes=[-1]](%719)\n",
      "  %722 : FloatTensor = onnx::Sub(%719, %721)\n",
      "  %723 : Tensor = onnx::Cast[to=1](%722)\n",
      "  %725 : Tensor = onnx::Pow(%723, %961)\n",
      "  %726 : Tensor = onnx::ReduceMean[axes=[-1]](%725)\n",
      "  %727 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %728 : FloatTensor = onnx::Add(%726, %727)\n",
      "  %729 : Tensor = onnx::Sqrt(%728)\n",
      "  %730 : FloatTensor = onnx::Div(%722, %729)\n",
      "  %731 : FloatTensor = onnx::Mul(%730, %distilbert.transformer.layer.4.output_layer_norm.weight)\n",
      "  %732 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%731, %distilbert.transformer.layer.4.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %733 : Tensor = onnx::Shape(%732)\n",
      "  %734 : Tensor = onnx::Constant[value={0}]()\n",
      "  %735 : Long(device=cpu) = onnx::Gather[axis=0](%733, %734) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:169:0\n",
      "  %736 : Tensor = onnx::Shape(%732)\n",
      "  %737 : Tensor = onnx::Constant[value={1}]()\n",
      "  %738 : Long(device=cpu) = onnx::Gather[axis=0](%736, %737) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:170:0\n",
      "  %740 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%732, %962) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %741 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%740, %distilbert.transformer.layer.5.attention.q_lin.bias)\n",
      "  %745 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %749 : Tensor = onnx::Concat[axis=0](%745, %963, %964, %965)\n",
      "  %750 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%741, %749) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %751 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%750) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %753 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%732, %966) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %754 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%753, %distilbert.transformer.layer.5.attention.k_lin.bias)\n",
      "  %758 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %762 : Tensor = onnx::Concat[axis=0](%758, %967, %968, %969)\n",
      "  %763 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%754, %762) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %765 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%732, %970) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %766 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%765, %distilbert.transformer.layer.5.attention.v_lin.bias)\n",
      "  %770 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %774 : Tensor = onnx::Concat[axis=0](%770, %971, %972, %973)\n",
      "  %775 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Reshape(%766, %774) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %776 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%775) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:180:0\n",
      "  %777 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %778 : Float(1:10752, 12:64, 14:768, 64:1, requires_grad=1, device=cpu) = onnx::Div(%751, %777)\n",
      "  %779 : Float(1:10752, 12:64, 64:1, 14:768, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%763) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %780 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MatMul(%778, %779) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:191:0\n",
      "  %781 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %782 : Bool(1:14, 14:1, requires_grad=0, device=cpu) = onnx::Equal(%114, %781) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\tensor.py:27:0\n",
      "  %785 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %788 : Tensor = onnx::Unsqueeze[axes=[0]](%738)\n",
      "  %789 : Tensor = onnx::Concat[axis=0](%785, %974, %975, %788)\n",
      "  %790 : Bool(1:14, 1:14, 1:14, 14:1, requires_grad=0, device=cpu) = onnx::Reshape(%782, %789) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %791 : Tensor = onnx::Shape(%780)\n",
      "  %792 : Bool(1:14, 12:0, 14:0, 14:1, requires_grad=0, device=cpu) = onnx::Expand(%790, %791) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:192:0\n",
      "  %793 : Tensor = onnx::Cast[to=9](%792)\n",
      "  %794 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %795 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Where(%793, %794, %780)\n",
      "  %796 : Float(1:2352, 12:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%795) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %797 : Float(1:10752, 12:896, 14:64, 64:1, requires_grad=1, device=cpu) = onnx::MatMul(%796, %776) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:202:0\n",
      "  %798 : Float(1:10752, 14:768, 12:64, 64:1, requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%797) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %801 : Tensor = onnx::Unsqueeze[axes=[0]](%735)\n",
      "  %804 : Tensor = onnx::Concat[axis=0](%801, %976, %977)\n",
      "  %805 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Reshape(%798, %804) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:184:0\n",
      "  %807 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%805, %978) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %808 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%807, %distilbert.transformer.layer.5.attention.out_lin.bias)\n",
      "  %809 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%808, %732) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:276:0\n",
      "  %811 : Tensor = onnx::ReduceMean[axes=[-1]](%809)\n",
      "  %812 : FloatTensor = onnx::Sub(%809, %811)\n",
      "  %813 : Tensor = onnx::Cast[to=1](%812)\n",
      "  %815 : Tensor = onnx::Pow(%813, %979)\n",
      "  %816 : Tensor = onnx::ReduceMean[axes=[-1]](%815)\n",
      "  %817 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %818 : FloatTensor = onnx::Add(%816, %817)\n",
      "  %819 : Tensor = onnx::Sqrt(%818)\n",
      "  %820 : FloatTensor = onnx::Div(%812, %819)\n",
      "  %821 : FloatTensor = onnx::Mul(%820, %distilbert.transformer.layer.5.sa_layer_norm.weight)\n",
      "  %822 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%821, %distilbert.transformer.layer.5.sa_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:2095:0\n",
      "  %824 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::MatMul(%822, %980) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %825 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Add(%824, %distilbert.transformer.layer.5.ffn.lin1.bias)\n",
      "  %826 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %827 : FloatTensor = onnx::Div(%825, %826)\n",
      "  %828 : Tensor = onnx::Erf(%827)\n",
      "  %829 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %830 : FloatTensor = onnx::Add(%828, %829)\n",
      "  %831 : FloatTensor = onnx::Mul(%825, %830)\n",
      "  %832 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %833 : Float(1:43008, 14:3072, 3072:1, requires_grad=1, device=cpu) = onnx::Mul(%831, %832) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1383:0\n",
      "  %835 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::MatMul(%833, %981) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1692:0\n",
      "  %836 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%835, %distilbert.transformer.layer.5.ffn.lin2.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %837 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%836, %822) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:280:0\n",
      "  %839 : Tensor = onnx::ReduceMean[axes=[-1]](%837)\n",
      "  %840 : FloatTensor = onnx::Sub(%837, %839)\n",
      "  %841 : Tensor = onnx::Cast[to=1](%840)\n",
      "  %843 : Tensor = onnx::Pow(%841, %982)\n",
      "  %844 : Tensor = onnx::ReduceMean[axes=[-1]](%843)\n",
      "  %845 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
      "  %846 : FloatTensor = onnx::Add(%844, %845)\n",
      "  %847 : Tensor = onnx::Sqrt(%846)\n",
      "  %848 : FloatTensor = onnx::Div(%840, %847)\n",
      "  %849 : FloatTensor = onnx::Mul(%848, %distilbert.transformer.layer.5.output_layer_norm.weight)\n",
      "  %850 : Float(1:10752, 14:768, 768:1, requires_grad=1, device=cpu) = onnx::Add(%849, %distilbert.transformer.layer.5.output_layer_norm.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %851 : Tensor = onnx::Constant[value={0}]()\n",
      "  %852 : Float(1:10752, 768:1, requires_grad=1, device=cpu) = onnx::Gather[axis=1](%850, %851) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\transformers\\modeling_distilbert.py:651:0\n",
      "  %853 : Float(1:768, 768:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%852, %pre_classifier.weight, %pre_classifier.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  %854 : Float(1:768, 768:1, requires_grad=1, device=cpu) = onnx::Relu(%853) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %855 : Float(1:2, 2:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%854, %classifier.weight, %classifier.bias) # C:\\Users\\chiecha.REDMOND\\Miniconda3\\envs\\azureml\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  return (%855)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "#enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "enc = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "#text = \"[CLS] Who was Jim Henson ?\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "\n",
    "# for deubg\n",
    "print(\"tokenized_text: {}\".format(tokenized_text))\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "print(\"indexed_tokens: {}\".format(indexed_tokens))\n",
    "segments_ids = [0]\n",
    "\n",
    "# Creating a dummy input\n",
    "# but you need to move tensors to GPU\n",
    "#https://github.com/huggingface/transformers/issues/227\n",
    "# discuss convertion\n",
    "#https://discuss.pytorch.org/t/best-way-to-convert-a-list-to-a-tensor/59949/2\n",
    "#torch.tensor\n",
    "#tokens_tensor = torch.tensor([indexed_tokens])\n",
    "#segments_tensors = torch.tensor([segments_ids])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"create input for device: {}\".format(device))\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "dummy_input = tokens_tensor\n",
    "\n",
    "\n",
    "# for debug\n",
    "print(\"tokens_tensor shape for chunk: {}\".format(tokens_tensor[0].shape[0])) \n",
    "for token_tensor in tokens_tensor:\n",
    "    print(\"token_tensor shape for chunk: {}\".format(token_tensor.shape[0]))\n",
    "\n",
    "\n",
    "# for deubg\n",
    "# 14 tokens for output\n",
    "print(\"tokens_tensor shape: {}\".format(tokens_tensor.shape))\n",
    "print(\"segments_tensor shape: {}\".format(segments_tensors.shape))\n",
    "\n",
    "print(\"tokens_tensor: {}\".format(tokens_tensor))\n",
    "print(\"segments_tensor: {}\".format(segments_tensors))\n",
    "\n",
    "\n",
    "# Initializing the model with the torchscript flag\n",
    "# Flag set to True even though it is not necessary as this model does not have an LM Head.\n",
    "#config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "#    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, torchscript=True)\n",
    "\n",
    "# Instantiating the model\n",
    "#model = BertModel(config)\n",
    "\n",
    "# The model needs to be in evaluation mode\n",
    "#model.eval()\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "# classfication only  0 and 1 so set ut to 2\n",
    "num_labels = 2\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels,\n",
    "                                                            output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.onnx.export(model, dummy_input, 'traced_distill_bert.onnx', verbose=True)\n",
    "\n",
    "\n",
    "# if want to want to download, uncomment it \n",
    "#torch.jit.save(traced_model, \"traced_distill_bert.pt\")"
   ]
  },
  {
   "source": [
    "apply_chunking_to_forward() test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}