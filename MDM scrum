

===================
people aether experiement  04132021
===================

answer
aether more feature
aether://experiments/efd64cc7-72e7-446d-927a-3014c5e1b957


aether TVS only
f764a122-84f9-4e13-9468-abebc531d337


===================
TULG for multi lingual
===================
TULGv1 (aka ZCodev2)  Release Announcement

===================
TNLR news letter  04132021
===================

<email_title>
Turing NLR Newsletter: April 2021

https://msasg.visualstudio.com/Bing_and_IPG/_wiki/wikis/Bing_and_IPG.wiki/46074/Turing-Language-Representation-Models


Compressed Models (6-12 layer, 13-33M parameters, 256-384 hidden)
Model	Model and Config location	Supported Framework (Pytorch/Tensorflow)

//soho 跟TNLR v3 做的  目前release 的版本
// ? 可能有一個是yue 給了6個layers 可能之後看
Turing NLR v3 Small, XSmall and Tiny (uncased)	\\FSU\Shares\TuringShare\NLR_Models\Monolingual\NLRv3-Compressed-Uncased	PT Only
Turing NLR v3 Small, XSmall and Tiny (+TransferDistil, uncased)	\\FSU\Shares\TuringShare\NLR_Models\Monolingual\NLRv3-Compressed-TransferDistil-Uncased	Both

// 之後會有個talk...
// soho 也有做multilingual


// soho 可能也會在TNLR v3 ongoing 繼續做


目前感覺 distill 跟yue 的check point 比較


size from 小到大
\\FSU\Shares\TuringShare\NLR_Models\Monolingual\NLRv3-Compressed-TransferDistil-Uncased\Tiny
\\FSU\Shares\TuringShare\NLR_Models\Monolingual\NLRv3-Compressed-TransferDistil-Uncased\XSmall = TNLR_minilm_sixlayer
\\FSU\Shares\TuringShare\NLR_Models\Monolingual\NLRv3-Compressed-TransferDistil-Uncased\Small = TNLR_minilm






=======
miniLM
=======
Yue,  Haoda
need to get miniLM and get it done






=======
repos
=======

mulan , international model
https://mulan-docs.azurewebsites.net/blogs/overview/

meta , wait for haoda
https://msasg.visualstudio.com/DefaultCollection/LanguageUnderstanding/_git/MetaST?path=%2Fsrc


my own repo
https://dev.azure.com/msasg/LanguageUnderstanding/_git/MyFilesApp?path=%2FMDM_DL_training%2FMDM_train_horovod_joint_intent_slot_TNLR_for_review.py



=======
spaCy
=======

[11:28 AM] Paulo Salem da Silva
    
I'm using my FHL project to learn about this NLP Python lib: spaCy · Industrial-strength Natural Language Processing in Python. This looks very powerful and convenient, and I heard a lot of good things about it. It is kind of a NLTK with a lot of Deep Learning under the hood and designed for industry, not academia. It can do NER, PoS tagging, dependency parsing, etc., for several languages out-of-the-box. Opinions about it? Are there better libs for the same job?
​[11:32 AM] Haoda Chu
    I love spaCy smile 
There is another one I found really interesting, which focused more on academia,  https://guide.allennlp.org/
(1 liked)<https://teams.microsoft.com/l/message/19:e27745fc0d644da2b605bafe5f31b309@thread.skype/1616437718284?tenantId=72f988bf-86f1-41af-91ab-2d7cd011db47&amp;groupId=0e62b139-e8ff-471b-aab4-a8edbd680f10&amp;parentMessageId=1616437718284&amp;teamName=User Understanding&amp;channelName=Modeling Methodology&amp;createdTime=1616437718284>

=======
GPT meeting summization
=======
https://microsoft.sharepoint.com/teams/Substrate_and_Query_Intelligence/_layouts/OneNote.aspx?id=%2Fteams%2FSubstrate_and_Query_Intelligence%2FShared%20Documents%2FTeam%20Documents%2FOXO%20keypoints%2FOXO%20Keypoints&wd=target%28Meeting%20Summarization%2FProjects.one%7C80FF9A39-4447-4564-B57D-C122E81D535F%2FGPT3%20on%20AMI%20Dataset%7C3E0C6546-645B-4330-B2CC-EE970C5D1509%2F%29


offensive content detection
https://microsoft.sharepoint.com/teams/SmartReplyDNN/_layouts/OneNote.aspx?id=%2Fteams%2FSmartReplyDNN%2FSiteAssets%2FSmart%20Reply%20Notebook&wd=target%28Horizontal%20Investments.one%7C3D3FB55C-33A6-4AC8-A563-0DD6EDB7B6EE%2FOffensive%20Content%20Detection%7C7B31B063-B734-4775-8EE3-9CD8371515A4%2F%29

gpt-3 access sheet
https://microsoft.sharepoint.com/:w:/t/msai/Eaez0c8QottNu_THuCqEuq4BJvSNY-ZJVKlJ9dgCzBSGrg?e=MBXkYf

For Jennifer about access to GPT-3:
For FHL requests, they should just reach out to me via email and I can help them. If we run into capacity issues, we will revisit at that time. 

If it is not related to FHL, but for longer term use beyond the FHL period, have them email me and I will send them to the access form to request access through those channels.


==================
pme MDM pr , evaluation how to setup
==================
https://msasg.visualstudio.com/Cortana/_git/CoreScienceDataStaging/pullrequest/2126517?_a=files&path=%2Fsrc%2FCopyModels%2FCLUv3TargetConfig.xml


===============================
clu debugger demo
===============================
from uu monthly meeting
https://microsoft-my.sharepoint-df.com/:v:/p/dolange/EUuH1sQoJZpKizYQsH1OD4YBA3QrswqR3cS8MxQ3OA2urQ


===============================
email search aether evaluation
================================
aether://experiments/5131fa25-4e20-4b28-9a4b-40e956d804e1


=========================
modeling methdology 
=========================
0218 brown bag
https://microsoftapc.sharepoint.com/teams/CLU705/_layouts/15/Doc.aspx?sourcedoc=%7B030809f7-103c-4303-b1e1-fe0440ea4f6e%7D&action=edit&wd=target%28Scrums.one%7Cb3222388-ea29-44ad-835f-d26ad0e395e7%2F2-18%7Ce7fec698-ae57-4815-aa8e-797fa77cc4a6%2F%29&wdorigin=703&wdpreservelink=1

email search term
Knowledge distillation: 

Goal: mimic the behavior of larger model using smaller student model 

General distillation/Task agnostic distillation. Such as MiniLM, TinyBert,MobileBERT,  and TransferDistill 
miniLM has paperes
https://github.com/microsoft/unilm/tree/master/minilm
for english uncase
MiniLMv1-L12-H384-uncased: 12-layer, 384-hidden, 12-heads, 33M parameters, 2.7x faster than BERT-Base
MiniLMv1-L6-H384-uncased: 6-layer, 384-hidden, 12-heads, 22M parameters, 5.3x faster than BERT-Base
MiniLMv1-L6-H768-uncased: 6-layer, 768-hidden, 12-heads, 66M parameters, 2.0x faster than BERT-Base

tingbert
https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT
has data augmentation, not sure how it works

mobile bert
mention quantization
https://github.com/google-research/google-research/tree/master/mobilebert

cannot find 
TransferDistill 



Task-agonistic LM ---- general distillation---> Task-agnostic compact LM-------> downstream finetuning 

task-agonistic 
paper
問看看是不是這樣
https://arxiv.org/pdf/2002.10957.pdf
Task-agonistic LM ---- general distillation---> Task-agnostic compact LM-------> downstream finetuning 

Pro: Can be leveraged by multiple downstream tasks 

Con: General distillation is usually more challenging and is still a research topic 

Task specific distillation 

Task-agonistic LM --->Downstream finetuning---> Task specific distillation 

Pro: Finetuning with larger checking usually can give us decent results 

Cons: when you have multiple downstream tasks, you have do task-specific distillation multiple times 

Quantization  

Mixed precision training with FP16 
代表性paper
https://arxiv.org/pdf/1805.10387.pdf

Quantization aware of training with int8 or even binary operator 

Post Quantization (CPU architecture) 
    // 好像xinjie 說只有memorization 的optimization
    Dynamic 

     Static 

Quantization with distillation 

… 

Hardware Speedup 

GPU/FPGA 

Graph optimization with onnx runtime 

Pruning 

Select sub network 


=========================
'other' intent map to fallback domain 
=========================
but in intent.txt
it does not specific which domain




===============================
AAAI 2021 introduction
===============================
General, I've just posted a detailed review of the recent AAAI 2021 conference (which I attended virtually) on the MSAI blog: Highlights from AAAI 2021 with takeaways for Microsoft - MSAI Team Blog (sharepoint.com)
 
Ming wants the Science team to occasionally publish there, and for some years now I've been writing summaries for my conference experiences, so this seems like a natural fit. Despite being a summary, there are actually a lot of details and screenshots, so I also intend to have a brownbag to discuss with everyone some of the most interesting points. Of course there's no way to absorb a whole (or even a large fraction) of these enormous conferences, so I think one of the best uses for them is to actually promote a broad reflection on our own problems, techniques and products, and help to define what to study next. Not to mention to have fun
https://microsoft.sharepoint.com/teams/msai/blog/Lists/Posts/Post.aspx?List=73493ef5%2D2d18%2D4b44%2Db031%2D516631016a50&ID=150&Source=https%3A%2F%2Fmicrosoft%2Esharepoint%2Ecom%2Fteams%2Fmsai%2Fblog%2FLists%2FPosts%2FAllPosts%2Easpx&ContentTypeId=0x0110002C9A0BA5E2F00441BF5718C1433830F5

===============================
obj # 6 scrum
===============================
[2/11/2021]
3 x 3 -> will discuss, presented

xinjie has playbook can be read for international

scripts 










===============================
thomas pan  talk changed adapter, we can learn
===============================
adapter  in talk

adapter: task specific parameters
adapater layer
https://arxiv.org/pdf/1902.00751.pdf



===============================
regular embedding  in rankder
===============================
embedding 

cannot look up embedding  for indexing


===============================
project alexandar newsletter
===============================
<email_title>
TNLR v4
Project Alexander Newsletter January 2021

但是TNLR 好像是case 的


===================
MDM sepearted 8 qpc
===================
file://YANHU-SUZHOU/Users/yanhu/Desktop/MDM_MLM_onboard/tvs_assistant_clu_refactored_by_domain
// 最大的qpc
assistant_enus_tvs_mv1.queryprocessingconfiguration.

所有的domain 改成import
encoder=qd_encoder
=>
encoder=mdm_mv1::qd_encoder with import mdm_mv1=assistant_enus_tvs_uber_mv1(這個有自己的qpc, 然後各個subdomain 都要用的) 

正常的domain
calendar=qd_calendar
=>
calendar=calendar_mv1::qd_calendar
calendar_mv1=assistant_enus_tvs_calendar_mv1 wtih import 的qpc 
assistant_enus_tvs_calendar_mv1.queryprocessingconfiguration 內部會再用到uber 裡面的encoder 還有rule 的pipeline

cmf_generic 是為了要 clu studio 的 query context,  clu studio 的preproceesed query 還是從 qd_encoder_tokenizer

但是拿raw Query 沒有考慮小寫   之後on board 要確定這次事情




===================
AMD GPU for usage
===================

<email_title>
FW: AMD MI50 GPU Cluster now available on AMLK8s/ITP


===================
compliant-lu from communication slot tagging
can learn from distillation from here
===================


01282021 video
https://msasg.visualstudio.com/DefaultCollection/LanguageUnderstanding/_git/compliant-lu
也是submit job 到AML  有空可以study

eran 基本上用這個做continual training
provide data 然後fine tune 之前的node
branch 是continual_325
https://msasg.visualstudio.com/DefaultCollection/LanguageUnderstanding/_git/compliant-lu?path=%2Fteacher_student_training%2Faml_pipeline%2FAml_continual_training_pipeline.py



<below 要ask haoda for confirmation>

aml_data_upload.ipynb 可能是要update data
https://msasg.visualstudio.com/DefaultCollection/LanguageUnderstanding/_git/compliant-lu?path=%2Fteacher_student_training%2Fnotebook

bert_distill_communicatio.ipynb 可能是跑distillation data
可以之後try try


====================================
retired dataset
====================================

https://msasg.visualstudio.com/Cortana/_git/CoreScienceDataStaging/pullrequest/2013251?_a=files

====================================
azure ml compliant gpu cluster
====================================


[9:56 AM] Haoda Chu
    这个cluster 不能在local用 只能用他们compliant aml的api access (得用compliant Aether)
​[9:56 AM] Haoda Chu
    目前只能这样, 他们有限制
​[9:56 AM] Haoda Chu
    而且还要申请比较多的权限
​[9:56 AM] Haoda Chu
    我找下documentation给你 你可以试试
​[9:57 AM] Chieh-Chun Chang
    oh 了解 
​[9:58 AM] Haoda Chu
    https://dev.azure.com/msdata/Vienna/_wiki/wikis/aml-1p-onboarding/15091/Aether-for-compliant-experimentation
​[9:58 AM] Haoda Chu
    你可以follow一下这里的流程
​[9:58 AM] Haoda Chu
    还挺详细的 不过估计要一会 权限申请起来慢


[9:58 AM] Haoda Chu
    https://dev.azure.com/msdata/Vienna/_wiki/wikis/aml-1p-onboarding/15091/Aether-for-compliant-experimentation
​[9:58 AM] Haoda Chu
    你可以follow一下这里的流程
​[9:58 AM] Haoda Chu
    还挺详细的 不过估计要一会 权限申请起来慢




======================
frisbee test failure
======================


frisbee test 01302021
with our flight
https://microsoft-my.sharepoint-df.com/personal/yuantu_microsoft_com/_layouts/15/onedrive.aspx?originalPath=aHR0cHM6Ly9taWNyb3NvZnQtbXkuc2hhcmVwb2ludC1kZi5jb20vOmY6L3AveXVhbnR1L0VqUVh1aE8zOUxGSHN1amtMQWVIbW9ZQlFDMGJaRk91Mmk5TlAyWGM5RTc3SXc%5FcnRpbWU9cVJIckI4bkUyRWc&id=%2Fpersonal%2Fyuantu%5Fmicrosoft%5Fcom%2FDocuments%2FWorkPlace%2Fshared%2FLU%2FMDM%2F20210129%2D164212
yc share 的folder 下面有summary page
這個 TestRunLog.xml 下面有first turn 的xml
https://microsoft-my.sharepoint-df.com/personal/yuantu_microsoft_com/_layouts/15/onedrive.aspx?originalPath=aHR0cHM6Ly9taWNyb3NvZnQtbXkuc2hhcmVwb2ludC1kZi5jb20vOmY6L3AveXVhbnR1L0VvdWVmZFAyMXVsTGc2UmtiSFlkTXI4QnJvb0lRUU45TWNsLUMwWm1PRFZuUFE%5FcnRpbWU9a2pMMjE5dkcyRWc&id=%2Fpersonal%2Fyuantu%5Fmicrosoft%5Fcom%2FDocuments%2FWorkPlace%2Fshared%2FLU%2FMDM%2F20210129%2D164212%5FLUflight%2F5babbdf1%2D92a7%2D4ac1%2D9c0a%2D169beca7c3e1%2D202101%2D3%5F0%2FTestRunLog%2Ehtml&parent=%2Fpersonal%2Fyuantu%5Fmicrosoft%5Fcom%2FDocuments%2FWorkPlace%2Fshared%2FLU%2FMDM%2F20210129%2D164212%5FLUflight%2F5babbdf1%2D92a7%2D4ac1%2D9c0a%2D169beca7c3e1%2D202101%2D3%5F0



frisbee page  011120201

Yes, red color is regarded as real and related regression; blue color means seemingly not related regression

//teamsaction command
Query:
PS E:\CoreScienceDataStaging\datasources\Files\queryclassificationprocessing> .\QCSQueryLabelWithLES.exe --externalFeaturesColumn 2 --queryInColumn 1 --interactive --verbose --encoding utf-8 --legacyAllowUnusedParameters -c E:\searchgold\deploy\builds\data\answers\QAS12HttpQAS  --variant cortana_teamsaction_enus_mv1 -dl teamsaction

// teamsaction multi turn 
first one , acute angle (first turn is go to channel)


first one:
根據yue 因該是這個condition 加的
所以也是regression
https://nlp-platform/clu/cortana/debug/scenario?clientId=Microsoft_Teams_enus_Microsoft&env=HttpQas-O365-Prod&vs=Cortana&query=first%20one&ClientContext_ReferenceTime=2021-01-12T18:44:03.829Z&PreviousTurnDomain=teamsaction&TaskFrameEntityStates=PromptedForSelection


acute angle 也是second turn 也是regression


// show me my call
should be teamspace_navigate, not calendar domain

// go to settings
this is ondevice and we do not have it 

// go to teams activity
// teams should not being tagged as contact_name











https://microsoftapc.sharepoint.com/teams/CLU705/_layouts/15/Doc.aspx?sourcedoc={75f33d6e-4674-4c39-bd74-112bf8e821ae}&action=edit&wd=target%28%E2%9A%92%20Feature%20Teams%2F%E2%99%BE%20Multi-Domain%20Modeling%2F%E2%9C%94%20Weekly.one%7Cbce2b8cc-7710-4f50-81ce-f8efc087b0e5%2FFrisbee%20testing%20DSAT%7C72557559-5980-4aac-9a27-f00347e131c2%2F%29





====================================
MDM model quality, shift to prod tickets

====================================
https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdev.azure.com%2Fmsasg%2F678b9503-3ecd-4823-8af7-d44814b0aff2%2F_workitems%2Fedit%2F3182439%3Ftracking_data%3DeyJTb3VyY2UiOiJFbWFpbCIsIlR5cGUiOiJOb3RpZmljYXRpb24iLCJTSUQiOiJtcy52c3Mtd29yay5teS13b3JraXRlbS1hc3NpZ25lZC10by1jaGFuZ2VzLXN1YnNjcmlwdGlvbiIsIlNUeXBlIjoiQ09OIiwiUmVjaXAiOjEsIl94Y2kiOnsiTklEIjoxODIwNzUyNDksIk1SZWNpcCI6Im0wPTEgIiwiQWN0IjoiYmUxYWY1YTgtNzFhNS00NDEzLWE4MmYtYmQ3MjM0NzUxOGY0In0sIkVsZW1lbnQiOiJoZXJvL2N0YSJ9&data=04%7C01%7CChiehChun.Chang%40microsoft.com%7Cd4523a57b7c74db59f9a08d8b0d1d90b%7C72f988bf86f141af91ab2d7cd011db47%7C0%7C0%7C637453762626260828%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=3%2FJgCnD9LQOwumD4G4F9Vem4Y3LHJVQz9HSEYeZdHJY%3D&reserved=0
https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdev.azure.com%2Fmsasg%2F678b9503-3ecd-4823-8af7-d44814b0aff2%2F_workitems%2Fedit%2F3182437%3Ftracking_data%3DeyJTb3VyY2UiOiJFbWFpbCIsIlR5cGUiOiJOb3RpZmljYXRpb24iLCJTSUQiOiJtcy52c3Mtd29yay5teS13b3JraXRlbS1hc3NpZ25lZC10by1jaGFuZ2VzLXN1YnNjcmlwdGlvbiIsIlNUeXBlIjoiQ09OIiwiUmVjaXAiOjEsIl94Y2kiOnsiTklEIjoxODIwNzUyNDQsIk1SZWNpcCI6Im0wPTEgIiwiQWN0IjoiMDA1MTMyMTYtMzM0Yy00YjhlLTk5MDgtYTYyNzdlY2YyNTdhIn0sIkVsZW1lbnQiOiJoZXJvL2N0YSJ9&data=04%7C01%7CChiehChun.Chang%40microsoft.com%7C31fe70f67fcb49dfa4f808d8b0d1d7c2%7C72f988bf86f141af91ab2d7cd011db47%7C0%7C0%7C637453762612838554%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=tA3QBwajTyy3uAVsm2TgHGrHCqVcHBJZj7868jqAjcE%3D&reserved=0
https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdev.azure.com%2Fmsasg%2F678b9503-3ecd-4823-8af7-d44814b0aff2%2F_workitems%2Fedit%2F3182436%3Ftracking_data%3DeyJTb3VyY2UiOiJFbWFpbCIsIlR5cGUiOiJOb3RpZmljYXRpb24iLCJTSUQiOiJtcy52c3Mtd29yay5teS13b3JraXRlbS1hc3NpZ25lZC10by1jaGFuZ2VzLXN1YnNjcmlwdGlvbiIsIlNUeXBlIjoiQ09OIiwiUmVjaXAiOjEsIl94Y2kiOnsiTklEIjoxODIwNzUyNDMsIk1SZWNpcCI6Im0wPTEgIiwiQWN0IjoiMDA1MTMyMTYtMzM0Yy00YjhlLTk5MDgtYTYyNzdlY2YyNTdhIn0sIkVsZW1lbnQiOiJoZXJvL2N0YSJ9&data=04%7C01%7CChiehChun.Chang%40microsoft.com%7C3b499ae6fa094bf8f34608d8b0d1d511%7C72f988bf86f141af91ab2d7cd011db47%7C0%7C0%7C637453762557800216%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=%2BKSxuCiqiqCu05ObeX5uOYBG0VqW%2BXOut9sIiSdYxgQ%3D&reserved=0
https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdev.azure.com%2Fmsasg%2F678b9503-3ecd-4823-8af7-d44814b0aff2%2F_workitems%2Fedit%2F3182438%3Ftracking_data%3DeyJTb3VyY2UiOiJFbWFpbCIsIlR5cGUiOiJOb3RpZmljYXRpb24iLCJTSUQiOiJtcy52c3Mtd29yay5teS13b3JraXRlbS1hc3NpZ25lZC10by1jaGFuZ2VzLXN1YnNjcmlwdGlvbiIsIlNUeXBlIjoiQ09OIiwiUmVjaXAiOjEsIl94Y2kiOnsiTklEIjoxODIwNzUyNDUsIk1SZWNpcCI6Im0wPTEgIiwiQWN0IjoiMDA1MTMyMTYtMzM0Yy00YjhlLTk5MDgtYTYyNzdlY2YyNTdhIn0sIkVsZW1lbnQiOiJoZXJvL2N0YSJ9&data=04%7C01%7CChiehChun.Chang%40microsoft.com%7C4f14adccd12542c30f9808d8b0d1d291%7C72f988bf86f141af91ab2d7cd011db47%7C0%7C0%7C637453762529156696%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=%2BgxA96K0GE9Sw9XLrPgHA4T3Qr35JimbWZLU8GV8WFU%3D&reserved=0



================================
caroline sync 
================================
01292021
新增了pattern for not tagging synonym  for meeting like 
class/lectre/course/appointment/event/meeting/schedule

有用到一些dropwords

model calendar process
https://microsoft-my.sharepoint.com/personal/dasilvac_microsoft_com/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fdasilvac%5Fmicrosoft%5Fcom%2FDocuments%2Ffor%5FC3&originalPath=aHR0cHM6Ly9taWNyb3NvZnQtbXkuc2hhcmVwb2ludC5jb20vOmY6L3AvZGFzaWx2YWMvRWxocVNNeHM3bEpMdTFPdldBdS1LQUFCVE9PNGNrMjFHbXFVVGhDRjItS0VMUT9ydGltZT1sRURyY2t6SDJFZw
model_calendar_planing.xlsx

you will see calendar bug progress shared by caroline

https://microsoft-my.sharepoint.com/personal/dasilvac_microsoft_com/_layouts/15/onedrive.aspx?originalPath=aHR0cHM6Ly9taWNyb3NvZnQtbXkuc2hhcmVwb2ludC5jb20vOmY6L3AvZGFzaWx2YWMvRWxocVNNeHM3bEpMdTFPdldBdS1LQUFCVE9PNGNrMjFHbXFVVGhDRjItS0VMUT9ydGltZT1sRURyY2t6SDJFZw&id=%2Fpersonal%2Fdasilvac%5Fmicrosoft%5Fcom%2FDocuments%2Ffor%5FC3%2FDataThatAreInTheLatestModel
lastest aether experiment to get training data

cortana_calendar_enus_mv10.domain.hotfix.modification.pipeline.txt
這個的最後seesion 有oost domian socre for synonsyms
有用到這個lexicon file cortana_calendar_enus_mv10.domain.patternMeetingSynonyms.txt

這個會直接compile 成一個bin file file 在這行被使用
MlgFeaturizer --in=BSS_STV --out=patternMeetingSynonyms --fts=cortana_calendar_enus_mv10.domain.patternMeetingSynonyms.bin --maxNGramLength=20

以後 MDM 需要可能可以使用 下面這個section

#####################
# Boost domain score to 0.6 for specific queries having lower model scores
# Bug 2962350: [Calendar] Words like "session", "review" and "discussion" should be treated as synonyms for meeting



=================================
calendar training data shared by caroline
=================================
https://microsoft-my.sharepoint.com/:f:/p/dasilvac/ElhqSMxs7lJLu1OvWAu-KAABTOO4ck21GmqUThCF2-KELQ?e=jmzG9M

01292021




=================================
calendar infile and pronoun
=================================
[1/19 12:58 PM] Caroline Santos Marques da Silva
    
Hey C3, regarding our last call, this is the FST rule to queries like "join this/that/it" 
define extrapronoun Ins(pronoun) EndTag("pronoun") LC([{​​​join}​​​] WS);
​[1/19 12:59 PM] Caroline Santos Marques da Silva
    
"pronoun" is only a text file with the pronouns "it/that/this"
​[1/19 1:00 PM] Caroline Santos Marques da Silva
    
you can find here: CoreScienceDataStaging\datasources\Calendar\PatternHotfix\Lexicons
​[1/19 1:00 PM] Caroline Santos Marques da Silva
    
and all FST rules are: \CoreScienceDataStaging\datasources\Calendar\PatternHotfix\Infiles
Edited


=================================
calendar bug fix ticket
=================================


//not yet include but only empty line extra
https://msasg.visualstudio.com/Cortana/_git/CoreScienceDataStaging/pullrequest/2016719?_a=files&path=%2Fdatasets%2FDefault%2FTest%2FMustpass_Default_Calendar_Golden.tsv

// include in 1/5/2021 v2
https://msasg.visualstudio.com/Cortana/_git/CoreScienceDataStaging/pullrequest/2010896?_a=files&path=%2Fdatasets%2FDefault%2FTest%2FMustpass_Default_Calendar_Golden.tsv

// include in 1/5/2021 v1
https://msasg.visualstudio.com/Cortana/_git/CoreScienceDataStaging/pullrequest/2008943?_a=files&path=%2Fdatasets%2FDefault%2FTest%2FMustpass_Default_Calendar_Golden.tsv


// include after 01212020
// but rules might not include
https://msasg.visualstudio.com/Cortana/_git/CoreScienceDataStaging/pullrequest/2033451?_a=files&path=%2Fdatasources%2FCalendar%2FPatternHotfix%2FInfiles%2Fcortana_calendar_enus_mv10.domain.pattern.tagger.extra.infile

====================================
TNLR, enterprice BERT
====================================
內部的希望我們都用這個

pretrain or fine tune 怎麼加feature ?
haoda 說有類似的work 以後可以看

bert offline experiment ticket
https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdev.azure.com%2Fmsasg%2F678b9503-3ecd-4823-8af7-d44814b0aff2%2F_workitems%2Fedit%2F3182466%3Ftracking_data%3DeyJTb3VyY2UiOiJFbWFpbCIsIlR5cGUiOiJOb3RpZmljYXRpb24iLCJTSUQiOiJtcy52c3Mtd29yay5teS13b3JraXRlbS1hc3NpZ25lZC10by1jaGFuZ2VzLXN1YnNjcmlwdGlvbiIsIlNUeXBlIjoiQ09OIiwiUmVjaXAiOjEsIl94Y2kiOnsiTklEIjoxODIwNzUyODcsIk1SZWNpcCI6Im0wPTEgIiwiQWN0IjoiOTdlMzUzNGEtMzA5MC00MTIzLThhMWEtMzAzMGU5NTViOWQ5In0sIkVsZW1lbnQiOiJoZXJvL2N0YSJ9&data=04%7C01%7CChiehChun.Chang%40microsoft.com%7C25a1a61db8b44047dafc08d8b0d1da65%7C72f988bf86f141af91ab2d7cd011db47%7C0%7C0%7C637453762649937211%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=0Wu02CZxSoDicqHxyRLynfPHqrCKF0sL5%2FouDWdSg8M%3D&reserved=0

wiki from Yue (also shared by Haoda)
can study and ask
https://msasg.visualstudio.com/Bing_and_IPG/_wiki/wikis/Bing_and_IPG.wiki/46074/Turing-Language-Representation-Models


question 1: 要填一個form

office 365, user undersdanding 
先填這個

Your response was submitted. Please contact turing@microsoft.com if your security group join request does not get approved within 48 hours. 

question 3: TNLR v3 ?


====================================
MDM objective  #5  jan 1, 2020
====================================
need to get concrete items
features should from Eran
personal grammar
can be a minor improvement
refer to this draft OKR
https://microsoftapc.sharepoint.com/teams/CLU705/_layouts/15/Doc.aspx?sourcedoc={75f33d6e-4674-4c39-bd74-112bf8e821ae}&action=edit&wd=target%28%F0%9F%92%AD%20Planning%2FFY21%20Planning.one%7C4627a6c2-c3ac-40e6-a67a-4d12e9e2b330%2FDraft%20Proposal%7C930cbf96-cede-4711-a44c-d341f4b857da%2F%29&wdorigin=703



====================================
MDM model comparison aether template
====================================

from this link
onenote:#12\06\2020&section-id=%7BBCE2B8CC-7710-4F50-81CE-F8EFC087B0E5%7D&page-id=%7BA4F11FBB-DC68-44ED-AD21-2F5948D63B87%7D&end&base-path=https://microsoftapc.sharepoint.com/teams/CLU705/Shared%20Documents/User%20Understanding/%E2%9A%92%20Feature%20Teams/%E2%99%BE%20Multi-Domain%20Modeling/%E2%9C%94%20Weekly.one

aether://experiments/88c8ca4f-232f-4b6b-ab0d-352638b26eb8

==================
status page
==================
https://microsoftapc.sharepoint.com/:o:/r/teams/CLU705/_layouts/15/WopiFrame.aspx?sourcedoc={75f33d6e-4674-4c39-bd74-112bf8e821ae}&action=edit&wd=target%28%E2%9A%92%20Feature%20Teams%2F%E2%99%BE%20Multi%2DDomain%20Modeling%2F%E2%9C%94%20Weekly%2Eone%7CBCE2B8CC%2D7710%2D4F50%2D81CE%2DF8EFC087B0E5%2F10%5C%2F5%5C%2F2020%7CB6463D14%2D6E29%2D402A%2DAF52%2D3A1582DE756A%2F%29



V1   OOD is optional

haoda 有跑deep learing 的實驗for TVS 可以看看怎麼使用 但是Q1 不是這個goal

TriCRF / deep learning 有DSAT 的時候train 的並不是stable?  不是每次都work
這是一個好問題要想一下





10122020
runtime cortex - multi trun

speed for scraping


frisbee


ondevice?
ignore


daily job, do not check in to searchgold directly ? need to check in manually



high-domain score module
SR data pipeline  有用prod rin agaons SR data 然後0.99 抓出pattern 然後do daga augmentation 這樣可以catch up new featureus



